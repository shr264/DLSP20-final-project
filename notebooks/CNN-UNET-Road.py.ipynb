{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import sys\n",
    "import random\n",
    "import psutil\n",
    "\n",
    "import json\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "from skimage.measure import label\n",
    "from scipy.ndimage.morphology import distance_transform_edt\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rcParams['figure.figsize'] = [5, 5]\n",
    "matplotlib.rcParams['figure.dpi'] = 200\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torch.nn import init\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.autograd import Variable\n",
    "from collections import OrderedDict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "from data_helper import UnlabeledDataset, LabeledDataset\n",
    "from helper import collate_fn, draw_box\n",
    "from dice_loss import IoULoss\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0);\n",
    "\n",
    "# All the images are saved in image_folder\n",
    "# All the labels are saved in the annotation_csv file\n",
    "image_folder = '../../DLSP20Dataset/data'\n",
    "annotation_csv = '../../DLSP20Dataset/data/annotation.csv'\n",
    "\n",
    "#azure\n",
    "#image_folder = '../../data'\n",
    "#annotation_csv = '../../data/annotation.csv'\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = 'cpu'\n",
    "\n",
    "torch.cuda.is_available()\n",
    "\n",
    "\n",
    "# function to count number of parameters\n",
    "def get_n_params(model):\n",
    "    np=0\n",
    "    for p in list(model.parameters()):\n",
    "        np += p.nelement()\n",
    "    return np\n",
    "\n",
    "def order_points(pts):\n",
    "    from scipy.spatial import distance as dist\n",
    "    import numpy as np\n",
    "    \n",
    "    xSorted = pts[np.argsort(pts[:, 0]), :]\n",
    "\n",
    "    leftMost = xSorted[:2, :]\n",
    "    rightMost = xSorted[2:, :]\n",
    "\n",
    "    leftMost = leftMost[np.argsort(leftMost[:, 1]), :]\n",
    "    (tl, bl) = leftMost\n",
    "\n",
    "    D = dist.cdist(tl[np.newaxis], rightMost, \"euclidean\")[0]\n",
    "    (br, tr) = rightMost[np.argsort(D)[::-1], :]\n",
    "\n",
    "    return np.array([tl, tr, br, bl], dtype=\"float32\")\n",
    "\n",
    "def arrange_box(x1,y1):\n",
    "    box=np.array(list(zip(x1,y1)))\n",
    "    box=order_points(box)\n",
    "    return box\n",
    "\n",
    "def iou(box1, box2):\n",
    "    from shapely.geometry import Polygon\n",
    "    a = Polygon(torch.t(box1)).convex_hull\n",
    "    b = Polygon(torch.t(box2)).convex_hull\n",
    "    \n",
    "    return a.intersection(b).area / a.union(b).area\n",
    "\n",
    "#def iou(xy1,xy2):\n",
    "#    \n",
    "#    from shapely.geometry import Polygon\n",
    "#    \n",
    "#    boxA = Polygon(arrange_box(xy1[0],xy1[1])).buffer(1e-9)\n",
    "#    boxB = Polygon(arrange_box(xy2[0],xy2[1])).buffer(1e-9)\n",
    "#    \n",
    "#    try:\n",
    "#        return boxA.intersection(boxB).area / boxA.union(boxB).area\n",
    "#    except:\n",
    "#        print('Box 1:',xy1[0],xy1[1])\n",
    "#        print('Box 2:',xy2[0],xy2[1])\n",
    "#        sys.exit(1)\n",
    "\n",
    "def map_to_ground_truth(overlaps, print_it=False):\n",
    "    prior_overlap, prior_idx = overlaps.max(1)\n",
    "    if print_it: print(prior_overlap)\n",
    "#     pdb.set_trace()\n",
    "    gt_overlap, gt_idx = overlaps.max(0)\n",
    "    gt_overlap[prior_idx] = 1.99\n",
    "    for i,o in enumerate(prior_idx): gt_idx[o] = i\n",
    "    return gt_overlap,gt_idx\n",
    "\n",
    "def calculate_overlap(target_bb, predicted_bb):\n",
    "    overlaps = torch.zeros(target_bb.size(0),predicted_bb.size(0))\n",
    "\n",
    "    for j in range(overlaps.shape[0]):\n",
    "        for k in range(overlaps.shape[1]):\n",
    "            overlaps[j][k] = iou(target_bb[j],predicted_bb[k])\n",
    "            \n",
    "    return overlaps\n",
    "\n",
    "def one_hot_embedding(labels, num_classes):\n",
    "    return torch.eye(num_classes)[labels.data.cpu()]\n",
    "\n",
    "from skimage import draw\n",
    "import numpy as np\n",
    "\n",
    "def poly2mask(vertex_row_coords, vertex_col_coords, shape):\n",
    "    fill_row_coords, fill_col_coords = draw.polygon(vertex_row_coords, vertex_col_coords, shape)\n",
    "    mask = torch.zeros(shape, dtype=np.bool)\n",
    "    mask[fill_row_coords, fill_col_coords] = True\n",
    "    return mask\n",
    "\n",
    "def convert_to_binary_mask(corners, shape=(800,800)):\n",
    "    point_squence = torch.stack([corners[:, 0], corners[:, 1], corners[:, 3], corners[:, 2], corners[:, 0]])\n",
    "    x,y = point_squence.T[0].detach() * 10 + 400, -point_squence.T[1].detach() * 10 + 400\n",
    "    new_im = poly2mask(y, x, shape)\n",
    "    return new_im\n",
    "\n",
    "def create_conf_matrix(target, pred, debug=True):\n",
    "    import sys\n",
    "    \n",
    "    target = target.reshape(-1)\n",
    "    pred = pred.reshape(-1)\n",
    "    \n",
    "    if debug:\n",
    "        print('Target values:', target.unique())\n",
    "        print('Predicted values:', pred.unique())\n",
    "        print('Target shape:', target.shape)\n",
    "        print('Predicted shape:', pred.shape)\n",
    "    \n",
    "    nb_classes = max(target.unique())\n",
    "    if len(pred.unique()) > (nb_classes+1) :\n",
    "        print('More predicted classes than true classes')\n",
    "        sys.exit(1)\n",
    "        \n",
    "    conf_matrix = torch.zeros(nb_classes+1, nb_classes+1)\n",
    "    for t, p in zip(target, pred):\n",
    "        conf_matrix[t, p] += 1\n",
    "    \n",
    "    return conf_matrix\n",
    "\n",
    "def create_conf_matrix2(target, pred, debug=True):\n",
    "    import sys\n",
    "    \n",
    "    target = target.reshape(-1).cpu().numpy()\n",
    "    pred = pred.reshape(-1).cpu().numpy()\n",
    "    \n",
    "        \n",
    "    conf_matrix = torch.from_numpy(confusion_matrix(target, pred)).to(device)\n",
    "    threat_score = (1.0*conf_matrix[1,1])/(conf_matrix[1,1]+conf_matrix[1,0]+conf_matrix[0,1])\n",
    "    \n",
    "    #print('Threat Score: {}'.format(threat_score))\n",
    "    \n",
    "    return conf_matrix\n",
    "\n",
    "def classScores(conf_matrix):\n",
    "    print('Confusion matrix\\n', conf_matrix)\n",
    "    TP = conf_matrix.diag()\n",
    "    TN = torch.zeros_like(TP)\n",
    "    FP = torch.zeros_like(TP)\n",
    "    FN = torch.zeros_like(TP)\n",
    "    for c in range(conf_matrix.size(0)):\n",
    "        idx = torch.ones(conf_matrix.size(0)).byte()\n",
    "        idx[c] = 0\n",
    "        # all non-class samples classified as non-class\n",
    "        TN[c] = conf_matrix[idx.nonzero()[:, None], idx.nonzero()].sum() #conf_matrix[idx[:, None], idx].sum() - conf_matrix[idx, c].sum()\n",
    "        # all non-class samples classified as class\n",
    "        FP[c] = conf_matrix[idx, c].sum()\n",
    "        # all class samples not classified as class\n",
    "        FN[c] = conf_matrix[c, idx].sum()\n",
    "\n",
    "        print('Class {}\\nTP {}, TN {}, FP {}, FN {}'.format(\n",
    "            c, TP[c], TN[c], FP[c], FN[c]))\n",
    "        \n",
    "    return (TP.detach().cpu().numpy(), \n",
    "            TN.detach().cpu().numpy(), \n",
    "            FP.detach().cpu().numpy(), \n",
    "            FN.detach().cpu().numpy())\n",
    "\n",
    "def split_list(a_list):\n",
    "    half = len(a_list)//2\n",
    "    return a_list[:half], a_list[half:]\n",
    "\n",
    "# You shouldn't change the unlabeled_scene_index\n",
    "# The first 106 scenes are unlabeled\n",
    "unlabeled_scene_index = np.arange(106)\n",
    "# The scenes from 106 - 133 are labeled\n",
    "# You should devide the labeled_scene_index into two subsets (training and validation)\n",
    "labeled_scene_index = np.arange(106, 134)\n",
    "\n",
    "train_scene_index = np.random.choice(labeled_scene_index, int(np.ceil(0.9*len(labeled_scene_index))))\n",
    "\n",
    "test_scene_index = labeled_scene_index[np.isin(labeled_scene_index, train_scene_index, invert=True)]\n",
    "\n",
    "val_scene_index, test_scene_index = split_list(test_scene_index)\n",
    "\n",
    "\n",
    "#transform=torchvision.transforms.Compose([torchvision.transforms.RandomCrop((200,200)),\n",
    "#                                          torchvision.transforms.Resize((100,100)),\n",
    "#                                          torchvision.transforms.ToTensor(),\n",
    "#                              torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "#                             ])\n",
    "\n",
    "transform=torchvision.transforms.Compose([torchvision.transforms.Resize((200,200)),\n",
    "                                          torchvision.transforms.ToTensor(),\n",
    "#                              torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                             ])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "# The labeled dataset can only be retrieved by sample.\n",
    "# And all the returned data are tuple of tensors, since bounding boxes may have different size\n",
    "# You can choose whether the loader returns the extra_info. It is optional. You don't have to use it.\n",
    "labeled_trainset = LabeledDataset(image_folder=image_folder,\n",
    "                                  annotation_file=annotation_csv,\n",
    "                                  scene_index=train_scene_index,\n",
    "                                  transform=transform,\n",
    "                                  extra_info=True\n",
    "                                 )\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(labeled_trainset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=True, \n",
    "                                          num_workers=2, \n",
    "                                          collate_fn=collate_fn)\n",
    "\n",
    "labeled_testset = LabeledDataset(image_folder=image_folder,\n",
    "                                  annotation_file=annotation_csv,\n",
    "                                  scene_index=test_scene_index,\n",
    "                                  transform=transform,\n",
    "                                  extra_info=True\n",
    "                                 )\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(labeled_testset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=True, \n",
    "                                          num_workers=2, \n",
    "                                          collate_fn=collate_fn)\n",
    "\n",
    "def double_conv(in_channels, out_channels):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "        nn.LeakyReLU(negative_slope=0.1),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        #nn.Dropout(0.5),\n",
    "        nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "        nn.LeakyReLU(negative_slope=0.1),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        #nn.Dropout(0.5)\n",
    "    )   \n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self, n_class):\n",
    "        super().__init__()\n",
    "                \n",
    "        self.dconv_down1 = double_conv(3, 16)\n",
    "        self.dconv_down2 = double_conv(16, 32)\n",
    "        self.dconv_down3 = double_conv(32, 48)\n",
    "        self.dconv_down4 = double_conv(48, 64)        \n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)        \n",
    "        \n",
    "        self.dconv_up3 = double_conv(48 + 64, 48)\n",
    "        self.dconv_up2 = double_conv(32 + 48, 32)\n",
    "        self.dconv_up1 = double_conv(32 + 16, 16)\n",
    "        \n",
    "        \n",
    "        self.dconv_up0 = double_conv(6*16, 3*16)\n",
    "        self.dconv_up00 = double_conv(3*16,16)\n",
    "        \n",
    "        self.conv_last = nn.Conv2d(16, n_class, 1)\n",
    "        \n",
    "        \n",
    "    def forward_once(self, x):\n",
    "        conv1 = self.dconv_down1(x)\n",
    "        x = self.maxpool(conv1)\n",
    "\n",
    "\n",
    "        conv2 = self.dconv_down2(x)\n",
    "        x = self.maxpool(conv2)\n",
    "\n",
    "        \n",
    "        conv3 = self.dconv_down3(x)\n",
    "        x = self.maxpool(conv3)  \n",
    "\n",
    "        \n",
    "        x = self.dconv_down4(x)\n",
    "\n",
    "        \n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv3], dim=1)\n",
    "\n",
    "        \n",
    "        x = self.dconv_up3(x)\n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv2], dim=1)   \n",
    "\n",
    "        x = self.dconv_up2(x)\n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv1], dim=1)   \n",
    "        \n",
    "        x = self.dconv_up1(x)\n",
    "        return x\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = [self.forward_once(y) for y in x]\n",
    "        x = torch.cat(x,axis=1)\n",
    "        \n",
    "        x = self.upsample(x)\n",
    "        x = self.dconv_up0(x)\n",
    "        \n",
    "        x = self.upsample(x)\n",
    "        x = self.dconv_up00(x)\n",
    "        \n",
    "        out = self.conv_last(x)\n",
    "        \n",
    "        return torch.sigmoid(out)\n",
    "\n",
    "    \n",
    "def single_conv(in_channels, out_channels, padding=1):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, 3, padding=padding),\n",
    "        nn.LeakyReLU(negative_slope=0.1),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        #nn.Dropout(0.5)\n",
    "    )   \n",
    "\n",
    "def double_conv2(in_channels, out_channels, output_padding=0, non_lin=False):\n",
    "    if non_lin:\n",
    "        return nn.Sequential(nn.ConvTranspose2d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size=2,\n",
    "                stride=2,\n",
    "                output_padding=output_padding),\n",
    "            nn.LeakyReLU(negative_slope=0.1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            #nn.Dropout(0.5)\n",
    "                            )\n",
    "    else:\n",
    "        return nn.Sequential(nn.ConvTranspose2d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size=2,\n",
    "                stride=2,\n",
    "                output_padding=output_padding),\n",
    "            #nn.LeakyReLU(negative_slope=0.1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            #nn.Dropout(0.5)\n",
    "                            )\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "class UNet2(nn.Module):\n",
    "\n",
    "    def __init__(self, n_class):\n",
    "        super().__init__()\n",
    "                \n",
    "        self.dconv_down1 = double_conv(3, 16)\n",
    "        self.dconv_down2 = double_conv(16, 32)\n",
    "        self.dconv_down3 = double_conv(32, 48)\n",
    "        self.dconv_down4 = double_conv(48, 64)        \n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)     \n",
    "         \n",
    "        \n",
    "        self.dconv_up4 = double_conv2(64, 64, 0, non_lin=True)\n",
    "        self.dconv_up3 = double_conv2(48 + 64, 48, non_lin=True)\n",
    "        self.dconv_up2 = double_conv2(32 + 48, 32, non_lin=True)\n",
    "        self.dconv_up1 = double_conv2(32 + 16, 16, non_lin=True)\n",
    "        \n",
    "        \n",
    "        self.dconv_up0 = double_conv2(6*16, 3*16, non_lin=True)\n",
    "        self.dconv_up00 = double_conv2(3*16, 16, non_lin=True)\n",
    "        self.dconv_up000 = double_conv2(2*16,16)\n",
    "        \n",
    "        self.conv_last = nn.Conv2d(16, n_class, 1, stride=2)\n",
    "        \n",
    "    @staticmethod\n",
    "    def weight_init(m):\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            init.xavier_normal(m.weight)\n",
    "            init.constant(m.bias, 0)\n",
    "        \n",
    "        \n",
    "    def forward_once(self, x):\n",
    "        conv1 = self.dconv_down1(x)\n",
    "        x = self.maxpool(conv1)\n",
    "\n",
    "\n",
    "        conv2 = self.dconv_down2(x)\n",
    "        x = self.maxpool(conv2)\n",
    "\n",
    "        \n",
    "        conv3 = self.dconv_down3(x)\n",
    "        x = self.maxpool(conv3)  \n",
    "\n",
    "        \n",
    "        x = self.dconv_down4(x)\n",
    "\n",
    "        #print(x.shape)\n",
    "        #x = self.upsample(x) \n",
    "        x = self.dconv_up4(x)\n",
    "        #print(x.shape)\n",
    "        #print(conv3.shape)\n",
    "        x = torch.cat([x, conv3], dim=1)\n",
    "\n",
    "        \n",
    "        x = self.dconv_up3(x)        \n",
    "        x = torch.cat([x, conv2], dim=1)   \n",
    "\n",
    "        x = self.dconv_up2(x)       \n",
    "        x = torch.cat([x, conv1], dim=1)   \n",
    "        \n",
    "        x = self.dconv_up1(x)\n",
    "        return x\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = [self.forward_once(y) for y in x]\n",
    "        x = torch.cat(x,axis=1)\n",
    "        \n",
    "        x = self.dconv_up0(x)\n",
    "        \n",
    "        x = self.dconv_up00(x)\n",
    "        \n",
    "        out = self.conv_last(x)\n",
    "        \n",
    "        return torch.sigmoid(out)\n",
    "    \n",
    "    \n",
    "class UNetEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "                \n",
    "        self.dconv_down1 = double_conv(3, 16)\n",
    "        self.dconv_down2 = double_conv(16, 32)\n",
    "        self.dconv_down3 = double_conv(32, 48)\n",
    "        self.dconv_down4 = double_conv(48, 64)        \n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        \n",
    "    @staticmethod\n",
    "    def weight_init(m):\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            init.xavier_normal(m.weight)\n",
    "            init.constant(m.bias, 0)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        conv1 = self.dconv_down1(x)\n",
    "        x = self.maxpool(conv1)\n",
    "\n",
    "\n",
    "        conv2 = self.dconv_down2(x)\n",
    "        x = self.maxpool(conv2)\n",
    "\n",
    "        \n",
    "        conv3 = self.dconv_down3(x)\n",
    "        x = self.maxpool(conv3)  \n",
    "\n",
    "        \n",
    "        x = self.dconv_down4(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "    \n",
    "def unet_weight_map(y, wc=None, w0 = 10, sigma = 5):\n",
    "\n",
    "    \"\"\"\n",
    "    Generate weight maps as specified in the U-Net paper\n",
    "    for boolean mask.\n",
    "\n",
    "    \"U-Net: Convolutional Networks for Biomedical Image Segmentation\"\n",
    "    https://arxiv.org/pdf/1505.04597.pdf\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mask: Numpy array\n",
    "        2D array of shape (image_height, image_width) representing binary mask\n",
    "        of objects.\n",
    "    wc: dict\n",
    "        Dictionary of weight classes.\n",
    "    w0: int\n",
    "        Border weight parameter.\n",
    "    sigma: int\n",
    "        Border width parameter.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Numpy array\n",
    "        Training weights. A 2D array of shape (image_height, image_width).\n",
    "    \"\"\"\n",
    "\n",
    "    labels = label(y)\n",
    "    no_labels = labels == 0\n",
    "    label_ids = sorted(np.unique(labels))[1:]\n",
    "\n",
    "    if len(label_ids) > 1:\n",
    "        distances = np.zeros((y.shape[0], y.shape[1], len(label_ids)))\n",
    "\n",
    "        for i, label_id in enumerate(label_ids):\n",
    "            distances[:,:,i] = distance_transform_edt(labels != label_id)\n",
    "\n",
    "        distances = np.sort(distances, axis=2)\n",
    "        d1 = distances[:,:,0]\n",
    "        d2 = distances[:,:,1]\n",
    "        w = w0 * np.exp(-1/2*((d1 + d2) / sigma)**2) * no_labels\n",
    "    else:\n",
    "        w = np.zeros_like(y)\n",
    "    if wc:\n",
    "        class_weights = np.zeros_like(y)\n",
    "        for k, v in wc.items():\n",
    "            class_weights[y == k] = v\n",
    "        w = w + class_weights\n",
    "    return w\n",
    "\n",
    "\n",
    "def unet_weight_map(y, wc=None, w0 = 100, sigma = 3):\n",
    "\n",
    "    \"\"\"\n",
    "    Generate weight maps as specified in the U-Net paper\n",
    "    for boolean mask.\n",
    "\n",
    "    \"U-Net: Convolutional Networks for Biomedical Image Segmentation\"\n",
    "    https://arxiv.org/pdf/1505.04597.pdf\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mask: Numpy array\n",
    "        2D array of shape (image_height, image_width) representing binary mask\n",
    "        of objects.\n",
    "    wc: dict\n",
    "        Dictionary of weight classes.\n",
    "    w0: int\n",
    "        Border weight parameter.\n",
    "    sigma: int\n",
    "        Border width parameter.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Numpy array\n",
    "        Training weights. A 2D array of shape (image_height, image_width).\n",
    "    \"\"\"\n",
    "    y = y.cpu()\n",
    "    labels = label(y)\n",
    "    no_labels = labels == 0\n",
    "    label_ids = sorted(np.unique(labels))[1:]\n",
    "\n",
    "    if len(label_ids) > 1:\n",
    "        distances = np.zeros((y.shape[0], y.shape[1], len(label_ids)))\n",
    "\n",
    "        for i, label_id in enumerate(label_ids):\n",
    "            distances[:,:,i] = distance_transform_edt(labels != label_id)\n",
    "\n",
    "        distances = np.sort(distances, axis=2)\n",
    "        d1 = distances[:,:,0]\n",
    "        d2 = distances[:,:,1]\n",
    "        w = w0 * np.exp(-1/2*((d1 + d2) / sigma)**2) * no_labels\n",
    "    else:\n",
    "        w = np.zeros_like(y)\n",
    "    if wc:\n",
    "        class_weights = np.zeros_like(y)\n",
    "        for k, v in wc.items():\n",
    "            class_weights[y == k] = v\n",
    "        w = w + class_weights\n",
    "    return w\n",
    "\n",
    "def dice_loss(pred, target, smooth = 1.):\n",
    "    pred = pred.contiguous()\n",
    "    target = target.contiguous()    \n",
    "\n",
    "    intersection = (pred * target).sum(dim=2).sum(dim=2)\n",
    "    \n",
    "    loss = (1 - ((2. * intersection + smooth) / (pred.sum(dim=2).sum(dim=2) + target.sum(dim=2).sum(dim=2) + smooth)))\n",
    "    \n",
    "    return loss.mean()\n",
    "\n",
    "def dice_loss_weighted(pred, target, smooth = 1.):\n",
    "    \n",
    "    weight = torch.tensor([1/np.sqrt(5110000), 1/np.sqrt(10000)])\n",
    "    weight_ = weight[target.data.view(-1).long()].view_as(target).to(device)\n",
    "    \n",
    "    pred = pred.contiguous()\n",
    "    target = target.contiguous()    \n",
    "\n",
    "    intersection = (weight_ * pred * target).sum(dim=2).sum(dim=2)\n",
    "    \n",
    "    loss = (1 - ((2. * intersection + smooth) / (pred.sum(dim=2).sum(dim=2) + target.sum(dim=2).sum(dim=2) + smooth)))\n",
    "    \n",
    "    return loss.mean()\n",
    "\n",
    "# Reconstruction + KL divergence losses summed over all elements and batch\n",
    "\n",
    "def loss_function(x_hat, x, epoch=None):\n",
    "    #only weighted bCE for first 8 epochs\n",
    "    if epoch!=None and epoch < 15:\n",
    "        #weighted\n",
    "        weight = torch.tensor([1, 1000])\n",
    "        weight_ = weight[x.data.view(-1).long()].view_as(x).to(device)\n",
    "        BCE = nn.functional.binary_cross_entropy(\n",
    "            x_hat, x, reduction='none'\n",
    "        )\n",
    "        BCE = (BCE*weight_).mean()\n",
    "    else:\n",
    "        BCE = nn.functional.binary_cross_entropy(\n",
    "            x_hat, x, reduction='mean'\n",
    "        )\n",
    "    \n",
    "    DICE = dice_loss(x_hat, x)\n",
    "\n",
    "    return BCE + DICE\n",
    "\n",
    "def loss_function_unet(x_hat, x, epoch=None):\n",
    "    #only weighted bCE for first 8 epochs\n",
    "    batch_size = x.size(0)\n",
    "    weight_ = torch.zeros_like(x)\n",
    "    for i in range(batch_size):\n",
    "        weight_[i,0,:,:] = torch.from_numpy(unet_weight_map(x[i,0,:,:])).to(device)\n",
    "    BCE = nn.functional.binary_cross_entropy(\n",
    "        x_hat, x, reduction='none'\n",
    "    )\n",
    "    BCE = (BCE*weight_).mean()\n",
    "\n",
    "    return BCE \n",
    "\n",
    "def loss_function_weighted(x_hat, x, gamma=0.75, epoch=None):\n",
    "    #only weighted bCE for first 8 epochs\n",
    "    \n",
    "    #weighted\n",
    "    weight = torch.tensor([1/np.sqrt(5110000), 1/np.sqrt(10000)])\n",
    "    #weight = torch.tensor([1/(5110000), 1/(10000)])\n",
    "    weight_ = weight[x.data.view(-1).long()].view_as(x).to(device)\n",
    "    BCE = nn.functional.binary_cross_entropy(\n",
    "        x_hat, x, reduction='none'\n",
    "    )\n",
    "    BCE = (BCE*weight_).mean()\n",
    "\n",
    "    DICE = dice_loss_weighted(x_hat, x)\n",
    "\n",
    "    return (1-gamma)*BCE + gamma*DICE\n",
    "\n",
    "# Training and testing the VAE\n",
    "\n",
    "\n",
    "\n",
    "def train_validate_segmentation_model_BB(model,\n",
    "                                         loss_function,\n",
    "                                         optimizer,\n",
    "                                         scheduler,\n",
    "                                         threshold = 0.5,\n",
    "                                         num_epochs=25,\n",
    "                                         img_w=200,\n",
    "                                         img_h=200,\n",
    "                                         name='unet_single_2',\n",
    "                                         device=device):\n",
    "\n",
    "    bb_accuracy_list = []\n",
    "    threat_score_list = []\n",
    "    best_loss = 1000000000000000\n",
    "    epochs = num_epochs\n",
    "    for epoch in range(0, epochs + 1):\n",
    "        # Training\n",
    "        if epoch >= 0:  # test untrained net first\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            for i, data in enumerate(trainloader):\n",
    "                sample, target, road_image, extra = data\n",
    "                batch_size = len(road_image)\n",
    "                x = torch.zeros((batch_size,1,800,800))\n",
    "                #x[:,0,:,:] = 1.0*torch.stack(road_image).reshape(-1, 800, 800)\n",
    "                x[:,0,:,:] = torch.zeros((batch_size,800,800))\n",
    "                for i in range(batch_size):\n",
    "                    for cat, bb in zip(target[i]['category'], target[i]['bounding_box']):\n",
    "                        x[i,0,:,:] = 1.0*convert_to_binary_mask(bb)\n",
    "                x = x.to(device)\n",
    "                y = torch.stack(sample).reshape(6,-1,3,img_w,img_h).to(device)\n",
    "                # ===================forward=====================\n",
    "                x_hat = model(y)\n",
    "                loss = loss_function(x_hat, x)\n",
    "                train_loss += loss.item()\n",
    "                # ===================backward====================\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            # ===================log========================\n",
    "            print(f'====> Epoch: {epoch} Average loss: {train_loss / len(trainloader.dataset):.9f}')\n",
    "\n",
    "        means, logvars, labels = list(), list(), list()\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            test_loss = 0\n",
    "            correct = [0,0]\n",
    "            total = [0,0]\n",
    "            conf_matrices = [torch.zeros(2,2).to(device),torch.zeros(2,2).to(device)]\n",
    "            for batch_idx, data in enumerate(testloader):\n",
    "                sample, target, road_image, extra = data\n",
    "                batch_size = len(road_image)\n",
    "                x = torch.zeros((batch_size,1,800,800))\n",
    "                #x[:,0,:,:] = 1.0*torch.stack(road_image).reshape(-1, 800, 800)\n",
    "                x[:,0,:,:] = torch.zeros((batch_size,800,800))\n",
    "                for i in range(batch_size):\n",
    "                    for cat, bb in zip(target[i]['category'], target[i]['bounding_box']):\n",
    "                        x[i,0,:,:] = 1.0*convert_to_binary_mask(bb)\n",
    "                x = x.to(device) \n",
    "                y = torch.stack(sample).reshape(6,-1,3,img_w,img_h).to(device)\n",
    "\n",
    "                # ===================forward=====================\n",
    "                x_hat = model(y)\n",
    "                test_loss += loss_function(x_hat, x).item()\n",
    "                # =====================log=======================\n",
    "\n",
    "                i = 0\n",
    "                #print('='*100)\n",
    "                print('Channel:{}'.format(i))\n",
    "                correct[i] += (x_hat[:,i,:,:]>threshold).eq(\n",
    "                    (x[:,i,:,:]==1).data.view_as((\n",
    "                        x_hat[:,i,:,:]>threshold))).cpu().sum().item()\n",
    "                total[i] += x[:,i,:,:].nelement()\n",
    "\n",
    "                #if batch_idx % 100 == 0:\n",
    "                #    for k in range(0,49):\n",
    "                #        thld = 0.01+k*0.02\n",
    "                #        print('Confusion Matrix at threshold: {} for Channel {}'.format(thld, i))\n",
    "                #        print(create_conf_matrix2(1*(x[:,i,:,:]==1), 1*(x_hat[:,i,:,:]>thld)))\n",
    "                #        print('='*50)\n",
    "                #    print('='*75)\n",
    "                conf_matrices[i] += create_conf_matrix2(1*(x[:,i,:,:]==1), 1*(x_hat[:,i,:,:]>threshold))\n",
    "                #print('='*100)\n",
    "\n",
    "\n",
    "        bb_accuracy = 100. * correct[0] / total[0]\n",
    "\n",
    "        if test_loss < best_loss:\n",
    "            print('Updating best model')\n",
    "            best_loss = copy.deepcopy(test_loss)\n",
    "            best_model = copy.deepcopy(model)\n",
    "            torch.save(best_model.state_dict(), \n",
    "                       'models/'+name+'_model.pth')\n",
    "\n",
    "        TP, TN, FP, FN = classScores(conf_matrices[0])\n",
    "\n",
    "        threat_score = TP[1]*1.0/(TP[1]+FP[1]+FN[1])\n",
    "\n",
    "        scheduler.step(test_loss)\n",
    "        bb_accuracy_list.append(bb_accuracy)\n",
    "        threat_score_list.append(threat_score)\n",
    "        print(\"\"\"\\nTest set: Average loss: {:.9f}, \n",
    "        Accuracy BB: {}/{} ({:.9f}%) ,\n",
    "        BB: \n",
    "        TP {} \n",
    "        TN {}\n",
    "        FP {}\n",
    "        FN {}\n",
    "        Threat Score {}\"\"\".format(\n",
    "            test_loss, \n",
    "            correct[0], total[0], bb_accuracy,\n",
    "             TP[1], TN[1], FP[1], FN[1], threat_score))\n",
    "\n",
    "                #labels.append(y.detach())\n",
    "        # ===================log========================\n",
    "        #codes['y'].append(torch.cat(labels))\n",
    "        test_loss /= len(testloader.dataset)\n",
    "        print(f'====> Test set loss: {test_loss:.9f}')\n",
    "        fig = plt.figure(figsize=(10, 6))\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.imshow((x[0,0,:,:].squeeze()==1).detach().cpu().numpy(), cmap='binary')\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.imshow((x_hat[0,0,:,:].squeeze()>threshold).detach().cpu().numpy(), cmap='binary')\n",
    "        plt.savefig('imgs/'+name+'_plot_epoch_'+str(epoch)+'.png', dpi=150)\n",
    "        plt.close(fig)\n",
    "    # dictionary of lists  \n",
    "    dict = {'bb_accuracy': bb_accuracy_list, 'threat_score': threat_score_list} \n",
    "    pd.DataFrame(dict).to_csv(name+'_accuracy_ts_list.csv')\n",
    "\n",
    "    torch.save(model.state_dict(), 'models/'+name+'_model_final.pth')\n",
    "\n",
    "# Training and testing the VAE\n",
    "\n",
    "def train_validate_segmentation_model_Roadmap(model,\n",
    "                                         loss_function,\n",
    "                                         optimizer,\n",
    "                                         scheduler,\n",
    "                                         threshold = 0.5,\n",
    "                                         num_epochs=25,\n",
    "                                         img_w=200,\n",
    "                                         img_h=200,\n",
    "                                         name='unet_single_2_200z',\n",
    "                                         device=device):\n",
    "\n",
    "    bb_accuracy_list = []\n",
    "    threat_score_list = []\n",
    "    m_dict = Counter() \n",
    "    best_loss = 1000000000000000\n",
    "    epochs = num_epochs\n",
    "    for epoch in range(0, epochs + 1):\n",
    "        # Training\n",
    "        if epoch >= 0:  # test untrained net first\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            for i, data in enumerate(trainloader):\n",
    "                sample, target, road_image, extra = data\n",
    "                batch_size = len(road_image)\n",
    "                x = torch.zeros((batch_size,1,800,800))\n",
    "                x[:,0,:,:] = 1.0*torch.stack(road_image).reshape(-1, 800, 800)\n",
    "                #x[:,0,:,:] = torch.zeros((batch_size,800,800))\n",
    "                #for i in range(batch_size):\n",
    "                #    for cat, bb in zip(target[i]['category'], target[i]['bounding_box']):\n",
    "                #        x[i,0,:,:] = 1.0*convert_to_binary_mask(bb)\n",
    "                x = x.to(device)\n",
    "                y = torch.stack(sample).reshape(6,-1,3,img_w,img_h).to(device)\n",
    "                # ===================forward=====================\n",
    "                x_hat = model(y)\n",
    "                loss = loss_function(x_hat, x)\n",
    "                train_loss += loss.item()\n",
    "                # ===================backward====================\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            # ===================log========================\n",
    "            print(f'====> Epoch: {epoch} Average loss: {train_loss / len(trainloader.dataset):.9f}')\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            test_loss = 0\n",
    "            correct = [0,0]\n",
    "            total = [0,0]\n",
    "            conf_matrices = [torch.zeros(2,2).to(device),torch.zeros(2,2).to(device)]\n",
    "            for batch_idx, data in enumerate(testloader):\n",
    "                sample, target, road_image, extra = data\n",
    "                batch_size = len(road_image)\n",
    "                x = torch.zeros((batch_size,1,800,800))\n",
    "                x[:,0,:,:] = 1.0*torch.stack(road_image).reshape(-1, 800, 800)\n",
    "                #x[:,0,:,:] = torch.zeros((batch_size,800,800))\n",
    "                #for i in range(batch_size):\n",
    "                #    for cat, bb in zip(target[i]['category'], target[i]['bounding_box']):\n",
    "                #        x[i,0,:,:] = 1.0*convert_to_binary_mask(bb)\n",
    "                x = x.to(device) \n",
    "                y = torch.stack(sample).reshape(6,-1,3,img_w,img_h).to(device)\n",
    "\n",
    "                # ===================forward=====================\n",
    "                x_hat = model(y)\n",
    "                test_loss += loss_function(x_hat, x).item()\n",
    "                # =====================log=======================\n",
    "\n",
    "                i = 0\n",
    "                print('Channel:{}'.format(i))\n",
    "                correct[i] += (x_hat[:,i,:,:]>threshold).eq(\n",
    "                    (x[:,i,:,:]==1).data.view_as((\n",
    "                        x_hat[:,i,:,:]>threshold))).cpu().sum().item()\n",
    "                total[i] += x[:,i,:,:].nelement()\n",
    "\n",
    "                #if batch_idx % 100 == 0:\n",
    "                #    cur_threat_score = []\n",
    "                #    for k in range(0,49):\n",
    "                #        thld = 0.01+k*0.02\n",
    "                #        TP, TN, FP, FN = classScores(create_conf_matrix2(1*(x[:,i,:,:]==1), 1*(x_hat[:,i,:,:]>thld)))\n",
    "                #        cur_threat_score.append(TP[1]*1.0/(TP[1]+FP[1]+FN[1]))\n",
    "                #    m = max(cur_threat_score)\n",
    "                #    m_idx = [i for i, j in enumerate(cur_threat_score) if j == m]\n",
    "                #    print('Max threat score: {} at threshold: {}'.format(m,0.01+m_idx*0.02))\n",
    "                #    m_dict[0.01+m_idx*0.02] += 1\n",
    "                #    threshold = max(m_dict, key=m_dict.get)\n",
    "                conf_matrices[i] += create_conf_matrix2(1*(x[:,i,:,:]==1), 1*(x_hat[:,i,:,:]>threshold))\n",
    "                #print('='*100)\n",
    "\n",
    "\n",
    "        bb_accuracy = 100. * correct[0] / total[0]\n",
    "\n",
    "        if test_loss < best_loss:\n",
    "            print('Updating best model')\n",
    "            best_loss = copy.deepcopy(test_loss)\n",
    "            best_model = copy.deepcopy(model)\n",
    "            torch.save(best_model.state_dict(), \n",
    "                       'models/'+name+'_Roadmap_model.pth')\n",
    "\n",
    "        TP, TN, FP, FN = classScores(conf_matrices[0])\n",
    "\n",
    "        threat_score = TP[1]*1.0/(TP[1]+FP[1]+FN[1])\n",
    "\n",
    "        scheduler.step(test_loss)\n",
    "        bb_accuracy_list.append(bb_accuracy)\n",
    "        threat_score_list.append(threat_score)\n",
    "        print(\"\"\"\\nTest set: Average loss: {:.9f}, \n",
    "        Accuracy BB: {}/{} ({:.9f}%) ,\n",
    "        BB: \n",
    "        TP {} \n",
    "        TN {}\n",
    "        FP {}\n",
    "        FN {}\n",
    "        Threat Score {}\"\"\".format(\n",
    "            test_loss, \n",
    "            correct[0], total[0], bb_accuracy,\n",
    "             TP[1], TN[1], FP[1], FN[1], threat_score))\n",
    "\n",
    "                #labels.append(y.detach())\n",
    "        # ===================log========================\n",
    "        #codes['y'].append(torch.cat(labels))\n",
    "        test_loss /= len(testloader.dataset)\n",
    "        print(f'====> Test set loss: {test_loss:.9f}')\n",
    "        fig = plt.figure(figsize=(10, 6))\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.imshow((x[0,0,:,:].squeeze()==1).detach().cpu().numpy(), cmap='binary')\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.imshow((x_hat[0,0,:,:].squeeze()>threshold).detach().cpu().numpy(), cmap='binary')\n",
    "        plt.savefig('imgs/'+name+'_Roadmap_plot_epoch_'+str(epoch)+'.png', dpi=150)\n",
    "        plt.close(fig)\n",
    "    # dictionary of lists  \n",
    "    dict = {'bb_accuracy': bb_accuracy_list, 'threat_score': threat_score_list} \n",
    "    pd.DataFrame(dict).to_csv(name+'_Roadmap_accuracy_ts_list.csv')\n",
    "\n",
    "    torch.save(model.state_dict(), 'models/'+name+'_Roadmap_model_final.pth')\n",
    "\n",
    "iou_loss = IoULoss()\n",
    "\n",
    "def loss_function_iou(x_hat, x, gamma = 0.25):\n",
    "    \n",
    "    one_count = x.sum().cpu().item()\n",
    "    zero_count = x.nelement() - one_count\n",
    "    weight = torch.tensor([1/np.sqrt(zero_count), 1/np.sqrt(one_count)])\n",
    "    weight_ = weight[x.data.view(-1).long()].view_as(x).to(device)\n",
    "    BCE = nn.functional.binary_cross_entropy(\n",
    "        x_hat, x, reduction='none'\n",
    "    )\n",
    "    BCE = (BCE*weight_).mean()\n",
    "\n",
    "    IOU = iou_loss(x_hat, x)\n",
    "    \n",
    "    return gamma*BCE + (1-gamma)*IOU\n",
    "\n",
    "## Unet model supervised\n",
    "\n",
    "model = UNet2(1).to(device)\n",
    "# Setting the optimiser\n",
    "\n",
    "learning_rate = 3e-4\n",
    "\n",
    "optimizer = torch.optim.Adam( filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate)\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.75, 0.999))\n",
    "\n",
    "\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.99)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n",
    "                                                       mode='min', \n",
    "                                                       factor=0.1, \n",
    "                                                       patience=3,\n",
    "                                                       verbose=True)\n",
    "\n",
    "train_validate_segmentation_model_Roadmap(model=model,\n",
    "                                    loss_function=loss_function_iou,\n",
    "                                    optimizer=optimizer,\n",
    "                                    scheduler=scheduler,\n",
    "                                    threshold = 0.5,\n",
    "                                    num_epochs=25,\n",
    "                                    img_w=200,\n",
    "                                    img_h=200,\n",
    "                                    name='unet_single_2_200',\n",
    "                                    device=device)\n",
    "\n",
    "del model\n",
    "\n",
    "# Unet model tansfer w/o finetuning\n",
    "\n",
    "unetencoder = UNetEncoder().to(device)\n",
    "\n",
    "pretrained_dict = torch.load('models/rotation_learning_model_unet.pth', map_location=device)\n",
    "model_dict = unetencoder.state_dict()\n",
    "\n",
    "# 1. filter out unnecessary keys\n",
    "pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "# 2. overwrite entries in the existing state dict\n",
    "model_dict.update(pretrained_dict) \n",
    "# 3. load the new state dict\n",
    "unetencoder.load_state_dict(pretrained_dict)\n",
    "\n",
    "for param in unetencoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "class UNetTransfer(nn.Module):\n",
    "\n",
    "    def __init__(self, n_class):\n",
    "        super().__init__()\n",
    "                \n",
    "        self.dconv_down1 = unetencoder.dconv_down1\n",
    "        self.dconv_down2 = unetencoder.dconv_down2\n",
    "        self.dconv_down3 = unetencoder.dconv_down3\n",
    "        self.dconv_down4 = unetencoder.dconv_down4        \n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)     \n",
    "         \n",
    "        \n",
    "        self.dconv_up4 = double_conv2(64, 64, 1, non_lin=True)\n",
    "        self.dconv_up3 = double_conv2(48 + 64, 48, non_lin=True)\n",
    "        self.dconv_up2 = double_conv2(32 + 48, 32, non_lin=True)\n",
    "        self.dconv_up1 = double_conv2(32 + 16, 16, non_lin=True)\n",
    "        \n",
    "        \n",
    "        self.dconv_up0 = double_conv2(6*16, 3*16, non_lin=True)\n",
    "        self.dconv_up00 = double_conv2(3*16,2*16, non_lin=True)\n",
    "        self.dconv_up000 = double_conv2(2*16,16)\n",
    "        \n",
    "        self.conv_last = nn.Conv2d(16, n_class, 1, stride=2)\n",
    "        \n",
    "    @staticmethod\n",
    "    def weight_init(m):\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            init.xavier_normal(m.weight)\n",
    "            init.constant(m.bias, 0)\n",
    "        \n",
    "        \n",
    "    def forward_once(self, x):\n",
    "        conv1 = self.dconv_down1(x)\n",
    "        x = self.maxpool(conv1)\n",
    "\n",
    "\n",
    "        conv2 = self.dconv_down2(x)\n",
    "        x = self.maxpool(conv2)\n",
    "\n",
    "        \n",
    "        conv3 = self.dconv_down3(x)\n",
    "        x = self.maxpool(conv3)  \n",
    "\n",
    "        \n",
    "        x = self.dconv_down4(x)\n",
    "\n",
    "        #print(x.shape)\n",
    "        #x = self.upsample(x) \n",
    "        x = self.dconv_up4(x)\n",
    "        #print(x.shape)\n",
    "        #print(conv3.shape)\n",
    "        x = torch.cat([x, conv3], dim=1)\n",
    "\n",
    "        \n",
    "        x = self.dconv_up3(x)        \n",
    "        x = torch.cat([x, conv2], dim=1)   \n",
    "\n",
    "        x = self.dconv_up2(x)       \n",
    "        x = torch.cat([x, conv1], dim=1)   \n",
    "        \n",
    "        x = self.dconv_up1(x)\n",
    "        return x\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = [self.forward_once(y) for y in x]\n",
    "        x = torch.cat(x,axis=1)\n",
    "        \n",
    "        x = self.dconv_up0(x)\n",
    "        \n",
    "        x = self.dconv_up00(x)\n",
    "        \n",
    "        #x = self.dconv_up000(x)\n",
    "        \n",
    "        out = self.conv_last(x)\n",
    "        \n",
    "        return torch.sigmoid(out)\n",
    "\n",
    "model = UNetTransfer(1).to(device)\n",
    "# Setting the optimiser\n",
    "\n",
    "learning_rate = 3e-4\n",
    "\n",
    "optimizer = torch.optim.Adam( filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate)\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.75, 0.999))\n",
    "\n",
    "\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.99)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n",
    "                                                       mode='min', \n",
    "                                                       factor=0.1, \n",
    "                                                       patience=3,\n",
    "                                                       verbose=True)\n",
    "\n",
    "train_validate_segmentation_model_Roadmap(model=model,\n",
    "                                    loss_function=loss_function_iou,\n",
    "                                    optimizer=optimizer,\n",
    "                                    scheduler=scheduler,\n",
    "                                    threshold = 0.5,\n",
    "                                    num_epochs=25,\n",
    "                                    img_w=200,\n",
    "                                    img_h=200,\n",
    "                                    name='unet_single_2_200_transfer',\n",
    "                                    device=device)\n",
    "\n",
    "del model\n",
    "\n",
    "## Transfer Learning finetuned\n",
    "\n",
    "unetencoder = UNetEncoder().to(device)\n",
    "\n",
    "pretrained_dict = torch.load('models/rotation_learning_model_unet.pth', map_location=device)\n",
    "model_dict = unetencoder.state_dict()\n",
    "\n",
    "# 1. filter out unnecessary keys\n",
    "pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "# 2. overwrite entries in the existing state dict\n",
    "model_dict.update(pretrained_dict) \n",
    "# 3. load the new state dict\n",
    "unetencoder.load_state_dict(pretrained_dict)\n",
    "\n",
    "for param in unetencoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "class UNetTransfer(nn.Module):\n",
    "\n",
    "    def __init__(self, n_class):\n",
    "        super().__init__()\n",
    "                \n",
    "        self.dconv_down1 = unetencoder.dconv_down1\n",
    "        self.dconv_down2 = unetencoder.dconv_down2\n",
    "        self.dconv_down3 = unetencoder.dconv_down3\n",
    "        self.dconv_down4 = unetencoder.dconv_down4        \n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)     \n",
    "         \n",
    "        \n",
    "        self.dconv_up4 = double_conv2(64, 64, 1, non_lin=True)\n",
    "        self.dconv_up3 = double_conv2(48 + 64, 48, non_lin=True)\n",
    "        self.dconv_up2 = double_conv2(32 + 48, 32, non_lin=True)\n",
    "        self.dconv_up1 = double_conv2(32 + 16, 16, non_lin=True)\n",
    "        \n",
    "        \n",
    "        self.dconv_up0 = double_conv2(6*16, 3*16, non_lin=True)\n",
    "        self.dconv_up00 = double_conv2(3*16,2*16, non_lin=True)\n",
    "        self.dconv_up000 = double_conv2(2*16,16)\n",
    "        \n",
    "        self.conv_last = nn.Conv2d(16, n_class, 1, stride=2)\n",
    "        \n",
    "    @staticmethod\n",
    "    def weight_init(m):\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            init.xavier_normal(m.weight)\n",
    "            init.constant(m.bias, 0)\n",
    "        \n",
    "        \n",
    "    def forward_once(self, x):\n",
    "        conv1 = self.dconv_down1(x)\n",
    "        x = self.maxpool(conv1)\n",
    "\n",
    "\n",
    "        conv2 = self.dconv_down2(x)\n",
    "        x = self.maxpool(conv2)\n",
    "\n",
    "        \n",
    "        conv3 = self.dconv_down3(x)\n",
    "        x = self.maxpool(conv3)  \n",
    "\n",
    "        \n",
    "        x = self.dconv_down4(x)\n",
    "\n",
    "        #print(x.shape)\n",
    "        #x = self.upsample(x) \n",
    "        x = self.dconv_up4(x)\n",
    "        #print(x.shape)\n",
    "        #print(conv3.shape)\n",
    "        x = torch.cat([x, conv3], dim=1)\n",
    "\n",
    "        \n",
    "        x = self.dconv_up3(x)        \n",
    "        x = torch.cat([x, conv2], dim=1)   \n",
    "\n",
    "        x = self.dconv_up2(x)       \n",
    "        x = torch.cat([x, conv1], dim=1)   \n",
    "        \n",
    "        x = self.dconv_up1(x)\n",
    "        return x\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = [self.forward_once(y) for y in x]\n",
    "        x = torch.cat(x,axis=1)\n",
    "        \n",
    "        x = self.dconv_up0(x)\n",
    "        \n",
    "        x = self.dconv_up00(x)\n",
    "        \n",
    "        #x = self.dconv_up000(x)\n",
    "        \n",
    "        out = self.conv_last(x)\n",
    "        \n",
    "        return torch.sigmoid(out)\n",
    "\n",
    "model = UNetTransfer(1).to(device)\n",
    "# Setting the optimiser\n",
    "\n",
    "learning_rate = 3e-4\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.75, 0.999))\n",
    "\n",
    "\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.99)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n",
    "                                                       mode='min', \n",
    "                                                       factor=0.1, \n",
    "                                                       patience=3,\n",
    "                                                       verbose=True)\n",
    "\n",
    "train_validate_segmentation_model_Roadmap(model=model,\n",
    "                                    loss_function=loss_function_iou,\n",
    "                                    optimizer=optimizer,\n",
    "                                    scheduler=scheduler,\n",
    "                                    threshold = 0.5,\n",
    "                                    num_epochs=25,\n",
    "                                    img_w=200,\n",
    "                                    img_h=200,\n",
    "                                    name='unet_single_2_200_transfer_finetuned',\n",
    "                                    device=device)\n",
    "\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pDL",
   "language": "python",
   "name": "pdl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
