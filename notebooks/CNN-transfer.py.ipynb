{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import sys\n",
    "import random\n",
    "import psutil\n",
    "\n",
    "import math\n",
    "import json\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rcParams['figure.figsize'] = [5, 5]\n",
    "matplotlib.rcParams['figure.dpi'] = 200\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from data_helper import UnlabeledDataset, LabeledDataset\n",
    "from helper import collate_fn, draw_box\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0);\n",
    "\n",
    "# All the images are saved in image_folder\n",
    "# All the labels are saved in the annotation_csv file\n",
    "image_folder = '../../DLSP20Dataset/data'\n",
    "annotation_csv = '../../DLSP20Dataset/data/annotation.csv'\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "torch.cuda.is_available()\n",
    "\n",
    "\n",
    "# function to count number of parameters\n",
    "def get_n_params(model):\n",
    "    np=0\n",
    "    for p in list(model.parameters()):\n",
    "        np += p.nelement()\n",
    "    return np\n",
    "\n",
    "def order_points(pts):\n",
    "    from scipy.spatial import distance as dist\n",
    "    import numpy as np\n",
    "    \n",
    "    xSorted = pts[np.argsort(pts[:, 0]), :]\n",
    "\n",
    "    leftMost = xSorted[:2, :]\n",
    "    rightMost = xSorted[2:, :]\n",
    "\n",
    "    leftMost = leftMost[np.argsort(leftMost[:, 1]), :]\n",
    "    (tl, bl) = leftMost\n",
    "\n",
    "    D = dist.cdist(tl[np.newaxis], rightMost, \"euclidean\")[0]\n",
    "    (br, tr) = rightMost[np.argsort(D)[::-1], :]\n",
    "\n",
    "    return np.array([tl, tr, br, bl], dtype=\"float32\")\n",
    "\n",
    "def arrange_box(x1,y1):\n",
    "    box=np.array(list(zip(x1,y1)))\n",
    "    box=order_points(box)\n",
    "    return box\n",
    "\n",
    "def iou(box1, box2):\n",
    "    from shapely.geometry import Polygon\n",
    "    a = Polygon(torch.t(box1)).convex_hull\n",
    "    b = Polygon(torch.t(box2)).convex_hull\n",
    "    \n",
    "    return a.intersection(b).area / a.union(b).area\n",
    "\n",
    "#def iou(xy1,xy2):\n",
    "#    \n",
    "#    from shapely.geometry import Polygon\n",
    "#    \n",
    "#    boxA = Polygon(arrange_box(xy1[0],xy1[1])).buffer(1e-9)\n",
    "#    boxB = Polygon(arrange_box(xy2[0],xy2[1])).buffer(1e-9)\n",
    "#    \n",
    "#    try:\n",
    "#        return boxA.intersection(boxB).area / boxA.union(boxB).area\n",
    "#    except:\n",
    "#        print('Box 1:',xy1[0],xy1[1])\n",
    "#        print('Box 2:',xy2[0],xy2[1])\n",
    "#        sys.exit(1)\n",
    "\n",
    "def map_to_ground_truth(overlaps, print_it=False):\n",
    "    prior_overlap, prior_idx = overlaps.max(1)\n",
    "    if print_it: print(prior_overlap)\n",
    "#     pdb.set_trace()\n",
    "    gt_overlap, gt_idx = overlaps.max(0)\n",
    "    gt_overlap[prior_idx] = 1.99\n",
    "    for i,o in enumerate(prior_idx): gt_idx[o] = i\n",
    "    return gt_overlap,gt_idx\n",
    "\n",
    "def calculate_overlap(target_bb, predicted_bb):\n",
    "    overlaps = torch.zeros(target_bb.size(0),predicted_bb.size(0))\n",
    "\n",
    "    for j in range(overlaps.shape[0]):\n",
    "        for k in range(overlaps.shape[1]):\n",
    "            overlaps[j][k] = iou(target_bb[j],predicted_bb[k])\n",
    "            \n",
    "    return overlaps\n",
    "\n",
    "def one_hot_embedding(labels, num_classes):\n",
    "    return torch.eye(num_classes)[labels.data.cpu()]\n",
    "\n",
    "from skimage import draw\n",
    "import numpy as np\n",
    "\n",
    "def poly2mask(vertex_row_coords, vertex_col_coords, shape):\n",
    "    fill_row_coords, fill_col_coords = draw.polygon(vertex_row_coords, vertex_col_coords, shape)\n",
    "    mask = torch.zeros(shape, dtype=np.bool)\n",
    "    mask[fill_row_coords, fill_col_coords] = True\n",
    "    return mask\n",
    "\n",
    "def convert_to_binary_mask(corners, shape=(800,800)):\n",
    "    point_squence = torch.stack([corners[:, 0], corners[:, 1], corners[:, 3], corners[:, 2], corners[:, 0]])\n",
    "    x,y = point_squence.T[0].detach() * 10 + 400, -point_squence.T[1].detach() * 10 + 400\n",
    "    new_im = poly2mask(y, x, shape)\n",
    "    return new_im\n",
    "\n",
    "def create_conf_matrix(target, pred, debug=True):\n",
    "    import sys\n",
    "    \n",
    "    target = target.reshape(-1)\n",
    "    pred = pred.reshape(-1)\n",
    "    \n",
    "    if debug:\n",
    "        print('Target values:', target.unique())\n",
    "        print('Predicted values:', pred.unique())\n",
    "        print('Target shape:', target.shape)\n",
    "        print('Predicted shape:', pred.shape)\n",
    "    \n",
    "    nb_classes = max(target.unique())\n",
    "    if len(pred.unique()) > (nb_classes+1) :\n",
    "        print('More predicted classes than true classes')\n",
    "        sys.exit(1)\n",
    "        \n",
    "    conf_matrix = torch.zeros(nb_classes+1, nb_classes+1)\n",
    "    for t, p in zip(target, pred):\n",
    "        conf_matrix[t, p] += 1\n",
    "    \n",
    "    return conf_matrix\n",
    "\n",
    "def create_conf_matrix2(target, pred, debug=True):\n",
    "    import sys\n",
    "    \n",
    "    target = target.reshape(-1).cpu().numpy()\n",
    "    pred = pred.reshape(-1).cpu().numpy()\n",
    "    \n",
    "        \n",
    "    conf_matrix = torch.from_numpy(confusion_matrix(target, pred)).to(device)\n",
    "    \n",
    "    print('Threat Score: {}'.format((1.0*conf_matrix[1,1])/(conf_matrix[1,1]+conf_matrix[1,0]+conf_matrix[0,1])))\n",
    "    \n",
    "    return conf_matrix\n",
    "\n",
    "def classScores(conf_matrix):\n",
    "    print('Confusion matrix\\n', conf_matrix)\n",
    "    TP = conf_matrix.diag()\n",
    "    TN = torch.zeros_like(TP)\n",
    "    FP = torch.zeros_like(TP)\n",
    "    FN = torch.zeros_like(TP)\n",
    "    for c in range(conf_matrix.size(0)):\n",
    "        idx = torch.ones(conf_matrix.size(0)).byte()\n",
    "        idx[c] = 0\n",
    "        # all non-class samples classified as non-class\n",
    "        TN[c] = conf_matrix[idx.nonzero()[:, None], idx.nonzero()].sum() #conf_matrix[idx[:, None], idx].sum() - conf_matrix[idx, c].sum()\n",
    "        # all non-class samples classified as class\n",
    "        FP[c] = conf_matrix[idx, c].sum()\n",
    "        # all class samples not classified as class\n",
    "        FN[c] = conf_matrix[c, idx].sum()\n",
    "\n",
    "        print('Class {}\\nTP {}, TN {}, FP {}, FN {}'.format(\n",
    "            c, TP[c], TN[c], FP[c], FN[c]))\n",
    "        \n",
    "    return (TP.detach().cpu().numpy(), \n",
    "            TN.detach().cpu().numpy(), \n",
    "            FP.detach().cpu().numpy(), \n",
    "            FN.detach().cpu().numpy())\n",
    "\n",
    "def split_list(a_list):\n",
    "    half = len(a_list)//2\n",
    "    return a_list[:half], a_list[half:]\n",
    "\n",
    "\n",
    "# You shouldn't change the unlabeled_scene_index\n",
    "# The first 106 scenes are unlabeled\n",
    "unlabeled_scene_index = np.arange(106)\n",
    "# The scenes from 106 - 133 are labeled\n",
    "# You should devide the labeled_scene_index into two subsets (training and validation)\n",
    "labeled_scene_index = np.arange(106, 134)\n",
    "\n",
    "train_scene_index = np.random.choice(labeled_scene_index, int(np.ceil(0.8*len(labeled_scene_index))))\n",
    "\n",
    "test_scene_index = labeled_scene_index[np.isin(labeled_scene_index, train_scene_index,invert=True)]\n",
    "\n",
    "\n",
    "transform=torchvision.transforms.Compose([torchvision.transforms.Resize((256,256)),\n",
    "                                          torchvision.transforms.ToTensor(),\n",
    "                              torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                             ])\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "# The labeled dataset can only be retrieved by sample.\n",
    "# And all the returned data are tuple of tensors, since bounding boxes may have different size\n",
    "# You can choose whether the loader returns the extra_info. It is optional. You don't have to use it.\n",
    "labeled_trainset = LabeledDataset(image_folder=image_folder,\n",
    "                                  annotation_file=annotation_csv,\n",
    "                                  scene_index=train_scene_index,\n",
    "                                  transform=transform,\n",
    "                                  extra_info=True\n",
    "                                 )\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(labeled_trainset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=True, \n",
    "                                          num_workers=2, \n",
    "                                          collate_fn=collate_fn)\n",
    "\n",
    "labeled_testset = LabeledDataset(image_folder=image_folder,\n",
    "                                  annotation_file=annotation_csv,\n",
    "                                  scene_index=test_scene_index,\n",
    "                                  transform=transform,\n",
    "                                  extra_info=True\n",
    "                                 )\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(labeled_testset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=True, \n",
    "                                          num_workers=2, \n",
    "                                          collate_fn=collate_fn)\n",
    "\n",
    "class ConvLayer(nn.Module):\n",
    "    def __init__(self, \n",
    "                 in_channels, \n",
    "                 out_channels, \n",
    "                 kernel_size=3, \n",
    "                 stride=1, \n",
    "                 padding=0, \n",
    "                 bias = True, \n",
    "                 pool=False,\n",
    "                 mp_kernel_size=2, \n",
    "                 mp_stride=2):\n",
    "        super(ConvLayer, self).__init__()\n",
    "        if pool:\n",
    "            self.layer = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=bias),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.Dropout(0.5),\n",
    "                nn.LeakyReLU(negative_slope=0.1), ## nn.ReLU(), \n",
    "                nn.MaxPool2d(kernel_size=mp_kernel_size, stride=mp_stride))\n",
    "        else:\n",
    "            self.layer = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=bias),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.Dropout(0.5),\n",
    "                nn.LeakyReLU(negative_slope=0.1), ## nn.ReLU(), \n",
    "                )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n",
    "class LinearLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(LinearLayer, self).__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            torch.nn.Linear(in_features, out_features),\n",
    "            nn.BatchNorm1d(out_features),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.LeakyReLU(negative_slope=0.1) ## nn.ReLU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n",
    "class ConvTLayer(nn.Module):\n",
    "    def __init__(self, \n",
    "                 in_channels, \n",
    "                 out_channels, \n",
    "                 kernel_size=3, \n",
    "                 stride=1, \n",
    "                 padding=0, \n",
    "                 output_padding=0, \n",
    "                 unpool=False,\n",
    "                 mp_kernel_size=2, \n",
    "                 mp_stride=2):\n",
    "        super(ConvTLayer, self).__init__()\n",
    "        if unpool:\n",
    "            self.layer = nn.Sequential(\n",
    "                nn.ConvTranspose2d(in_channels, \n",
    "                                   out_channels, \n",
    "                                   kernel_size, \n",
    "                                   stride=stride, \n",
    "                                   padding=padding, \n",
    "                                   output_padding=output_padding, \n",
    "                                   bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.Dropout(0.5),\n",
    "                nn.LeakyReLU(negative_slope=0.1), ## nn.ReLU()\n",
    "                nn.MaxUnpool2d(kernel_size=mp_kernel_size, stride=mp_stride)\n",
    "            )\n",
    "        else:\n",
    "            self.layer = nn.Sequential(\n",
    "                nn.ConvTranspose2d(in_channels, \n",
    "                                   out_channels, \n",
    "                                   kernel_size, \n",
    "                                   stride=stride, \n",
    "                                   padding=padding, \n",
    "                                   output_padding=output_padding, \n",
    "                                   bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.Dropout(0.5),\n",
    "                nn.LeakyReLU(negative_slope=0.1), ## nn.ReLU()\n",
    "            )        \n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n",
    "class Encoder1(nn.Module):\n",
    "    def __init__(self, d):\n",
    "        super(Encoder1, self).__init__()\n",
    "        self.conv1 = ConvLayer(3,96, stride=2)\n",
    "        self.conv2 = ConvLayer(96,128, stride=2)\n",
    "        self.conv3 = ConvLayer(128,256, stride=2)\n",
    "        self.conv4 = ConvLayer(256,512, stride=2)\n",
    "        self.conv5 = ConvLayer(512,1024, stride=2)\n",
    "        self.conv6 = ConvLayer(1024,2048, stride=2)\n",
    "        self.lin1 = nn.Linear(2048*3*3, d)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.lin1(x.reshape(-1,2048*3*3))\n",
    "        return x\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, d=650, output_size=4):\n",
    "        super(CNN, self).__init__()\n",
    "        self.encoder = Encoder1(d=d)\n",
    "        self.linear = nn.Linear(d,4)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.linear(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, d=650):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.encoder = Encoder1(d=d)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return x\n",
    "\n",
    "class EncoderY(nn.Module):\n",
    "    def __init__(self,  d):\n",
    "        super(EncoderY, self).__init__()\n",
    "        self.conv1 = ConvLayer(3,96, stride=2)\n",
    "        self.conv2 = ConvLayer(96,128, stride=2)\n",
    "        self.conv3 = ConvLayer(128,256, stride=2)\n",
    "        self.conv4 = ConvLayer(256,512, stride=2)\n",
    "        self.conv5 = ConvLayer(512,1024, stride=2)\n",
    "        self.conv6 = ConvLayer(1024,2048, stride=2)\n",
    "        self.lin1 = nn.Linear(2048*3*3, d)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.conv6(x)\n",
    "        #print(x.shape)\n",
    "        x = self.lin1(x.reshape(-1,2048*3*3))\n",
    "        return x\n",
    "\n",
    "class EncoderX(nn.Module):\n",
    "    def __init__(self, d):\n",
    "        super(EncoderX, self).__init__()\n",
    "        self.conv1 = ConvLayer(1,16, stride=2)\n",
    "        self.conv2 = ConvLayer(16,32, stride=2)\n",
    "        self.conv3 = ConvLayer(32,48, stride=2)\n",
    "        self.conv4 = ConvLayer(48,64, stride=2)\n",
    "        self.conv5 = ConvLayer(64,96, stride=2)\n",
    "        self.conv6 = ConvLayer(96,128, stride=2)\n",
    "        self.conv7 = ConvLayer(128,256, stride=2)\n",
    "        self.conv8 = ConvLayer(256,512, stride=2)\n",
    "        self.lin1 = nn.Linear(512*2*2, d)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.conv7(x)\n",
    "        x = self.conv8(x)\n",
    "        #print(x.shape)\n",
    "        x = self.lin1(x.reshape(-1,512*2*2))\n",
    "        return x\n",
    "\n",
    "class DecoderX(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DecoderX, self).__init__()\n",
    "        self.convt1 = ConvTLayer(4096, 2048, kernel_size=3, stride=2)\n",
    "        self.convt2 = ConvTLayer(2048, 1024, kernel_size=3, stride=3, output_padding=(0,0))\n",
    "        self.convt3 = ConvTLayer(1024, 512, kernel_size=3, stride=2, padding=(1,1), output_padding=(0,0))\n",
    "        self.convt4 = ConvTLayer(512, 256, kernel_size=3, stride=3, padding=(1,1), output_padding=(0,0))\n",
    "        self.convt5 = ConvTLayer(256, 128, kernel_size=3, stride=2, output_padding=(0,0))\n",
    "        self.convt6 = ConvTLayer(128, 96, kernel_size=3, stride=2, output_padding=(0,0))\n",
    "        self.convt7 = ConvTLayer(96, 64, kernel_size=3, stride=2, output_padding=(0,0))\n",
    "        self.convt8 = ConvTLayer(64, 1, kernel_size=3, stride=2, output_padding=(1,1))\n",
    "        \n",
    "    def forward(self,z):\n",
    "        z = self.convt1(z)\n",
    "        z = self.convt2(z)\n",
    "        z = self.convt3(z)\n",
    "        z = self.convt4(z)\n",
    "        z = self.convt5(z)\n",
    "        z = self.convt6(z)\n",
    "        z = self.convt7(z)\n",
    "        z = self.convt8(z)\n",
    "        return torch.sigmoid(z)\n",
    "    \n",
    "# Defining the model\n",
    "\n",
    "# use dgcan weights\n",
    "encoder = Encoder()\n",
    "pretrained_dict = torch.load('models/DCGAN_D_generator_epoch_50.pth', map_location=device)\n",
    "model_dict = encoder.state_dict()\n",
    "\n",
    "# 1. filter out unnecessary keys\n",
    "pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "# 2. overwrite entries in the existing state dict\n",
    "model_dict.update(pretrained_dict) \n",
    "# 3. load the new state dict\n",
    "encoder.load_state_dict(pretrained_dict)\n",
    "\n",
    "for param in encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 6073.0\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'BCE' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0ee0acf5878c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0mx_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;31m#print(torch.min(x_hat),torch.max(x_hat))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;31m# ===================backward====================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-0ee0acf5878c>\u001b[0m in \u001b[0;36mloss_function\u001b[0;34m(x_hat, x, mu, logvar, epoch)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0mDICE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdice_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mBCE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mKLD\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mDICE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'BCE' referenced before assignment"
     ]
    }
   ],
   "source": [
    "class CNN_VAE_transfer(nn.Module):\n",
    "    def __init__(self, hidden_d=196, image_d=650): #hidden_d=196, image_d=650 or hidden_d=286, image_d=625\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d = hidden_d\n",
    "        self.id = image_d\n",
    "        \n",
    "        self.y_encoder = encoder\n",
    "\n",
    "        self.x_encoder = EncoderX(d=2*self.d)\n",
    "\n",
    "        self.x_decoder = DecoderX()\n",
    "\n",
    "    def reparameterise(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = logvar.mul(0.5).exp_()\n",
    "            eps = std.data.new(std.size()).normal_()\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        mu_logvar = self.x_encoder(x).view(-1, 2, self.d)\n",
    "        #print(mu_logvar.shape)\n",
    "        img_enc = [self.y_encoder(img.squeeze()) for img in y] \n",
    "        mu = mu_logvar[:, 0, :]\n",
    "        #print(mu.shape)\n",
    "        logvar = mu_logvar[:, 1, :]\n",
    "        #print(logvar.shape)\n",
    "        z = self.reparameterise(mu, logvar)\n",
    "        img_enc.append(z)\n",
    "        #print(torch.cat(img_enc,axis=1).shape)\n",
    "        out = torch.cat(img_enc,axis=1).reshape(-1,4096,1,1)\n",
    "        return self.x_decoder(out), mu, logvar\n",
    "    \n",
    "    def inference(self, y, mu=None, logvar=None):\n",
    "        N = y.size(1)\n",
    "        z = torch.randn((N, self.d)).to(device)\n",
    "        #print('Prior:',z.shape)\n",
    "        if mu is not None and logvar is not None:\n",
    "            #print(mu.shape)\n",
    "            #print(logvar.shape)\n",
    "            std = logvar.mul(0.5).exp_()\n",
    "            eps = std.data.new(std.size()).normal_()\n",
    "            z = eps.mul(std).add_(mu)\n",
    "            #print('Post:',z.shape)\n",
    "        z = z.reshape(-1,196)\n",
    "        img_enc = [self.y_encoder(img.squeeze()) for img in y] \n",
    "        img_enc.append(z)\n",
    "        out = torch.cat(img_enc,axis=1).reshape(-1,4096,1,1)\n",
    "        return self.x_decoder(out)\n",
    "    \n",
    "    \n",
    " \n",
    "    \n",
    "model = CNN_VAE_transfer().to(device)\n",
    "# Setting the optimiser\n",
    "\n",
    "learning_rate = 1e-2\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=learning_rate,\n",
    "    betas=(0.5, 0.999)\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n",
    "                                                       mode='min', \n",
    "                                                       factor=0.1, \n",
    "                                                       patience=5,\n",
    "                                                       verbose=True)\n",
    "\n",
    "def dice_loss(pred, target, smooth = 1.):\n",
    "    pred = pred.contiguous()\n",
    "    target = target.contiguous()    \n",
    "\n",
    "    intersection = (pred * target).sum(dim=2).sum(dim=2)\n",
    "    \n",
    "    loss = (1 - ((2. * intersection + smooth) / (pred.sum(dim=2).sum(dim=2) + target.sum(dim=2).sum(dim=2) + smooth)))\n",
    "    \n",
    "    return loss.sum()\n",
    "\n",
    "# Reconstruction + KL divergence losses summed over all elements and batch\n",
    "\n",
    "def loss_function(x_hat, x, mu, logvar, epoch=None):\n",
    "    #only weighted bCE for first 8 epochs\n",
    "    if epoch!=None and epoch < 8:\n",
    "        #weighted\n",
    "        weight = torch.tensor([1, 1000])\n",
    "        weight_ = weight[x.view(-1, 800*800).data.view(-1).long()].view_as(x.view(-1, 800*800)).to(device)\n",
    "        BCE = nn.functional.binary_cross_entropy(\n",
    "            x_hat.view(-1, 800*800), x.view(-1, 800*800), reduction='none'\n",
    "        )\n",
    "        BCE = (BCE*weight_).sum()\n",
    "    else:\n",
    "        try:\n",
    "            BCE = nn.functional.binary_cross_entropy(\n",
    "                x_hat.view(-1, 800*800), x.view(-1, 800*800), reduction='sum'\n",
    "            )\n",
    "        except RuntimeError:\n",
    "            print(x_hat.sum().item(), x.sum().item())\n",
    "    KLD = 0.5 * torch.sum(logvar.exp() - logvar - 1 + mu.pow(2))\n",
    "    \n",
    "    DICE = dice_loss(x_hat, x)\n",
    "\n",
    "    return BCE + KLD + DICE\n",
    "\n",
    "\n",
    "# Training and testing the VAE\n",
    "hidden_dim = 4096 - 6*650\n",
    "accuracy_list = []\n",
    "best_loss = 1000000\n",
    "threshold = 0.5\n",
    "epochs = 25\n",
    "codes = dict(μ=list(), logσ2=list(), y=list())\n",
    "for epoch in range(0, epochs + 1):\n",
    "    # Training\n",
    "    if epoch >= 0:  # test untrained net first\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for i, data in enumerate(trainloader):\n",
    "            sample, target, road_image, extra = data\n",
    "            batch_size = len(road_image)\n",
    "            x = torch.zeros((batch_size,1,800,800))\n",
    "            x[:,0,:,:] = torch.zeros((batch_size,800,800))\n",
    "            for i in range(batch_size):\n",
    "                for cat, bb in zip(target[i]['category'], target[i]['bounding_box']):\n",
    "                    x[i,0,:,:] = 1.0*convert_to_binary_mask(bb)\n",
    "            x = x.to(device) \n",
    "            #print(x.unique())\n",
    "            y = torch.stack(sample).reshape(6,-1,3,256,256).to(device)\n",
    "            # ===================forward=====================\n",
    "            x_hat, mu, logvar = model(x, y)\n",
    "            #print(torch.min(x_hat),torch.max(x_hat))\n",
    "            loss = loss_function(x_hat, x, mu, logvar)\n",
    "            train_loss += loss.item()\n",
    "            # ===================backward====================\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            if not math.isnan(loss.item()):\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "                optimizer.step()\n",
    "            else:\n",
    "                print('warning, NaN')\n",
    "            \n",
    "            optimizer.step()\n",
    "        # ===================log========================\n",
    "        print(f'====> Epoch: {epoch} Average loss: {train_loss / len(trainloader.dataset):.4f}')\n",
    "\n",
    "    means, logvars, labels = list(), list(), list()\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        test_loss_post = 0\n",
    "        test_loss_prior = 0\n",
    "        road_correct_post = 0\n",
    "        road_correct_prior = 0\n",
    "        total_road = 0\n",
    "        conf_matrix_road = torch.zeros(2,2).to(device)\n",
    "        for batch_idx, data in enumerate(testloader):\n",
    "            sample, target, road_image, extra = data\n",
    "            batch_size = len(road_image)\n",
    "            x = torch.zeros((batch_size,1,800,800))\n",
    "            x[:,0,:,:] = torch.zeros((batch_size,800,800))\n",
    "            for i in range(batch_size):\n",
    "                for cat, bb in zip(target[i]['category'], target[i]['bounding_box']):\n",
    "                    x[i,0,:,:] = 1.0*convert_to_binary_mask(bb)\n",
    "            x = x.to(device) \n",
    "            y = torch.stack(sample).reshape(6,-1,3,256,256).to(device)\n",
    "            \n",
    "            # ===================forward=====================\n",
    "            mu = torch.mean(mu,0).repeat(batch_size).view(batch_size,hidden_dim)\n",
    "            logvar = torch.mean(logvar,0).repeat(batch_size).view(batch_size,hidden_dim)\n",
    "            x_hat_post = model.inference(y, mu, logvar)\n",
    "            x_hat_prior = model.inference(y)\n",
    "            test_loss_post += loss_function(x_hat_post, x, mu, logvar, epoch=10).item()\n",
    "            test_loss_prior += loss_function(x_hat_prior, x, mu, logvar, epoch=10).item()\n",
    "            # =====================log=======================\n",
    "            means.append(mu.detach())\n",
    "            logvars.append(logvar.detach())\n",
    "            \n",
    "            road_correct_post += (x_hat_post>threshold).eq((x==1).data.view_as((x_hat_post>threshold))).cpu().sum().item()\n",
    "            road_correct_prior += (x_hat_prior>threshold).eq((x==1).data.view_as((x_hat_prior>threshold))).cpu().sum().item()\n",
    "            total_road += x.nelement()\n",
    "            \n",
    "            if batch_idx % 100 == 0:\n",
    "                for i in range(0,60):\n",
    "                    thld = 0.2+i*0.01\n",
    "                    print('Confusion Matrix (Post) at threshold: {}'.format(thld))\n",
    "                    print(create_conf_matrix2(1*(x==1), 1*(x_hat_post>thld)))\n",
    "                    print('='*50)\n",
    "                    print('Confusion Matrix (Prior) at threshold: {}'.format(thld))\n",
    "                    print(create_conf_matrix2(1*(x==1), 1*(x_hat_prior>thld)))\n",
    "                    print('='*50)\n",
    "                print('='*100)\n",
    "                print('='*100)\n",
    "            conf_matrix_road += create_conf_matrix2(1*(x==1), 1*(x_hat_post>threshold))\n",
    "                       \n",
    "    road_accuracy_post = 100. * road_correct_post / total_road\n",
    "    road_accuracy_prior = 100. * road_correct_prior / total_road\n",
    "    \n",
    "    if test_loss_post < best_loss:\n",
    "        print('Updating best model')\n",
    "        best_loss = copy.deepcopy(test_loss_post)\n",
    "        best_model = copy.deepcopy(model)\n",
    "        torch.save(best_model.state_dict(), \n",
    "                   'models/CNNVAE_transfer_BB_model.pth')\n",
    "\n",
    "        \n",
    "    scheduler.step(test_loss_post)\n",
    "    accuracy_list.append(road_accuracy_prior)\n",
    "    print(\"\"\"\\nTest set: Average loss: {:.4f}, \n",
    "    Accuracy Road (Post): {}/{} ({:.0f}%) ,\n",
    "    Accuracy Road (Prior): {}/{} ({:.0f}%) ,\n",
    "    Road: TP {} , \n",
    "    TN {}\n",
    "    FP {}\n",
    "    FN {}\"\"\".format(\n",
    "        test_loss_post, \n",
    "        road_correct_post, total_road, road_accuracy_post, \n",
    "        road_correct_prior, total_road, road_accuracy_prior, \n",
    "        *classScores(conf_matrix_road)))\n",
    "\n",
    "            #labels.append(y.detach())\n",
    "    # ===================log========================\n",
    "    codes['μ'].append(torch.cat(means))\n",
    "    codes['logσ2'].append(torch.cat(logvars))\n",
    "    #codes['y'].append(torch.cat(labels))\n",
    "    test_loss_post /= len(testloader.dataset)\n",
    "    test_loss_prior /= len(testloader.dataset)\n",
    "    print(f'====> Posterior Test set loss: {test_loss_post:.4f}')\n",
    "    print(f'====> Prior Test set loss: {test_loss_prior:.4f}')\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow((x[0].squeeze()==1).detach().cpu().numpy(), cmap='binary')\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow((x_hat_post[0].squeeze()>threshold).detach().cpu().numpy(), cmap='binary')\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.imshow((x_hat_prior[0].squeeze()>threshold).detach().cpu().numpy(), cmap='binary')\n",
    "    plt.savefig(\"imgs/CNNVAE_transfer_plot_epoch_\"+str(epoch)+\".png\", dpi=150)\n",
    "    plt.close(fig)\n",
    "    \n",
    "pd.DataFrame(accuracy_list).to_csv('CNNVAE_transfer_accuracy_list.csv')\n",
    "\n",
    "json = json.dumps(codes)\n",
    "f = open(\"CNNVAE_transfer_codes.json\",\"w\")\n",
    "f.write(json)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pDL",
   "language": "python",
   "name": "pdl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
