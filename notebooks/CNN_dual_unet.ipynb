{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import sys\n",
    "import random\n",
    "import psutil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rcParams['figure.figsize'] = [5, 5]\n",
    "matplotlib.rcParams['figure.dpi'] = 200\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from data_helper import UnlabeledDataset, LabeledDataset\n",
    "from helper import collate_fn, draw_box\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0);\n",
    "\n",
    "# All the images are saved in image_folder\n",
    "# All the labels are saved in the annotation_csv file\n",
    "image_folder = '../../DLSP20Dataset/data'\n",
    "annotation_csv = '../../DLSP20Dataset/data/annotation.csv'\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "torch.cuda.is_available()\n",
    "\n",
    "\n",
    "# function to count number of parameters\n",
    "def get_n_params(model):\n",
    "    np=0\n",
    "    for p in list(model.parameters()):\n",
    "        np += p.nelement()\n",
    "    return np\n",
    "\n",
    "def order_points(pts):\n",
    "    from scipy.spatial import distance as dist\n",
    "    import numpy as np\n",
    "    \n",
    "    xSorted = pts[np.argsort(pts[:, 0]), :]\n",
    "\n",
    "    leftMost = xSorted[:2, :]\n",
    "    rightMost = xSorted[2:, :]\n",
    "\n",
    "    leftMost = leftMost[np.argsort(leftMost[:, 1]), :]\n",
    "    (tl, bl) = leftMost\n",
    "\n",
    "    D = dist.cdist(tl[np.newaxis], rightMost, \"euclidean\")[0]\n",
    "    (br, tr) = rightMost[np.argsort(D)[::-1], :]\n",
    "\n",
    "    return np.array([tl, tr, br, bl], dtype=\"float32\")\n",
    "\n",
    "def arrange_box(x1,y1):\n",
    "    box=np.array(list(zip(x1,y1)))\n",
    "    box=order_points(box)\n",
    "    return box\n",
    "\n",
    "def iou(box1, box2):\n",
    "    from shapely.geometry import Polygon\n",
    "    a = Polygon(torch.t(box1)).convex_hull\n",
    "    b = Polygon(torch.t(box2)).convex_hull\n",
    "    \n",
    "    return a.intersection(b).area / a.union(b).area\n",
    "\n",
    "#def iou(xy1,xy2):\n",
    "#    \n",
    "#    from shapely.geometry import Polygon\n",
    "#    \n",
    "#    boxA = Polygon(arrange_box(xy1[0],xy1[1])).buffer(1e-9)\n",
    "#    boxB = Polygon(arrange_box(xy2[0],xy2[1])).buffer(1e-9)\n",
    "#    \n",
    "#    try:\n",
    "#        return boxA.intersection(boxB).area / boxA.union(boxB).area\n",
    "#    except:\n",
    "#        print('Box 1:',xy1[0],xy1[1])\n",
    "#        print('Box 2:',xy2[0],xy2[1])\n",
    "#        sys.exit(1)\n",
    "\n",
    "def map_to_ground_truth(overlaps, print_it=False):\n",
    "    prior_overlap, prior_idx = overlaps.max(1)\n",
    "    if print_it: print(prior_overlap)\n",
    "#     pdb.set_trace()\n",
    "    gt_overlap, gt_idx = overlaps.max(0)\n",
    "    gt_overlap[prior_idx] = 1.99\n",
    "    for i,o in enumerate(prior_idx): gt_idx[o] = i\n",
    "    return gt_overlap,gt_idx\n",
    "\n",
    "def calculate_overlap(target_bb, predicted_bb):\n",
    "    overlaps = torch.zeros(target_bb.size(0),predicted_bb.size(0))\n",
    "\n",
    "    for j in range(overlaps.shape[0]):\n",
    "        for k in range(overlaps.shape[1]):\n",
    "            overlaps[j][k] = iou(target_bb[j],predicted_bb[k])\n",
    "            \n",
    "    return overlaps\n",
    "\n",
    "def one_hot_embedding(labels, num_classes):\n",
    "    return torch.eye(num_classes)[labels.data.cpu()]\n",
    "\n",
    "from skimage import draw\n",
    "import numpy as np\n",
    "\n",
    "def poly2mask(vertex_row_coords, vertex_col_coords, shape):\n",
    "    fill_row_coords, fill_col_coords = draw.polygon(vertex_row_coords, vertex_col_coords, shape)\n",
    "    mask = torch.zeros(shape, dtype=np.bool)\n",
    "    mask[fill_row_coords, fill_col_coords] = True\n",
    "    return mask\n",
    "\n",
    "def convert_to_binary_mask(corners, shape=(800,800)):\n",
    "    point_squence = torch.stack([corners[:, 0], corners[:, 1], corners[:, 3], corners[:, 2], corners[:, 0]])\n",
    "    x,y = point_squence.T[0].detach() * 10 + 400, -point_squence.T[1].detach() * 10 + 400\n",
    "    new_im = poly2mask(y, x, shape)\n",
    "    return new_im\n",
    "\n",
    "def create_conf_matrix(target, pred, debug=True):\n",
    "    import sys\n",
    "    \n",
    "    target = target.reshape(-1)\n",
    "    pred = pred.reshape(-1)\n",
    "    \n",
    "    if debug:\n",
    "        print('Target values:', target.unique())\n",
    "        print('Predicted values:', pred.unique())\n",
    "        print('Target shape:', target.shape)\n",
    "        print('Predicted shape:', pred.shape)\n",
    "    \n",
    "    nb_classes = max(target.unique())\n",
    "    if len(pred.unique()) > (nb_classes+1) :\n",
    "        print('More predicted classes than true classes')\n",
    "        sys.exit(1)\n",
    "        \n",
    "    conf_matrix = torch.zeros(nb_classes+1, nb_classes+1)\n",
    "    for t, p in zip(target, pred):\n",
    "        conf_matrix[t, p] += 1\n",
    "    \n",
    "    return conf_matrix\n",
    "\n",
    "def create_conf_matrix2(target, pred, debug=True):\n",
    "    import sys\n",
    "    \n",
    "    target = target.reshape(-1).cpu().numpy()\n",
    "    pred = pred.reshape(-1).cpu().numpy()\n",
    "    \n",
    "        \n",
    "    conf_matrix = torch.from_numpy(confusion_matrix(target, pred)).to(device)\n",
    "    threat_score = (1.0*conf_matrix[1,1])/(conf_matrix[1,1]+conf_matrix[1,0]+conf_matrix[0,1])\n",
    "    \n",
    "    print('Threat Score: {}'.format(threat_score))\n",
    "    \n",
    "    return conf_matrix\n",
    "\n",
    "def classScores(conf_matrix):\n",
    "    print('Confusion matrix\\n', conf_matrix)\n",
    "    TP = conf_matrix.diag()\n",
    "    TN = torch.zeros_like(TP)\n",
    "    FP = torch.zeros_like(TP)\n",
    "    FN = torch.zeros_like(TP)\n",
    "    for c in range(conf_matrix.size(0)):\n",
    "        idx = torch.ones(conf_matrix.size(0)).byte()\n",
    "        idx[c] = 0\n",
    "        # all non-class samples classified as non-class\n",
    "        TN[c] = conf_matrix[idx.nonzero()[:, None], idx.nonzero()].sum() #conf_matrix[idx[:, None], idx].sum() - conf_matrix[idx, c].sum()\n",
    "        # all non-class samples classified as class\n",
    "        FP[c] = conf_matrix[idx, c].sum()\n",
    "        # all class samples not classified as class\n",
    "        FN[c] = conf_matrix[c, idx].sum()\n",
    "\n",
    "        print('Class {}\\nTP {}, TN {}, FP {}, FN {}'.format(\n",
    "            c, TP[c], TN[c], FP[c], FN[c]))\n",
    "        \n",
    "    return TP, TN, FP, FN\n",
    "\n",
    "def split_list(a_list):\n",
    "    half = len(a_list)//2\n",
    "    return a_list[:half], a_list[half:]\n",
    "\n",
    "\n",
    "# You shouldn't change the unlabeled_scene_index\n",
    "# The first 106 scenes are unlabeled\n",
    "unlabeled_scene_index = np.arange(106)\n",
    "# The scenes from 106 - 133 are labeled\n",
    "# You should devide the labeled_scene_index into two subsets (training and validation)\n",
    "labeled_scene_index = np.arange(106, 134)\n",
    "\n",
    "train_scene_index = np.random.choice(labeled_scene_index, int(np.ceil(0.8*len(labeled_scene_index))))\n",
    "\n",
    "test_scene_index = labeled_scene_index[np.isin(labeled_scene_index, train_scene_index,invert=True)]\n",
    "\n",
    "\n",
    "transform=torchvision.transforms.Compose([torchvision.transforms.Resize((200,200)),\n",
    "                                          torchvision.transforms.ToTensor(),\n",
    "                              torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                             ])\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "# The labeled dataset can only be retrieved by sample.\n",
    "# And all the returned data are tuple of tensors, since bounding boxes may have different size\n",
    "# You can choose whether the loader returns the extra_info. It is optional. You don't have to use it.\n",
    "labeled_trainset = LabeledDataset(image_folder=image_folder,\n",
    "                                  annotation_file=annotation_csv,\n",
    "                                  scene_index=train_scene_index,\n",
    "                                  transform=transform,\n",
    "                                  extra_info=True\n",
    "                                 )\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(labeled_trainset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=True, \n",
    "                                          num_workers=2, \n",
    "                                          collate_fn=collate_fn)\n",
    "\n",
    "labeled_testset = LabeledDataset(image_folder=image_folder,\n",
    "                                  annotation_file=annotation_csv,\n",
    "                                  scene_index=test_scene_index,\n",
    "                                  transform=transform,\n",
    "                                  extra_info=True\n",
    "                                 )\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(labeled_testset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=True, \n",
    "                                          num_workers=2, \n",
    "                                          collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_conv(in_channels, out_channels):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )   \n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self, n_class):\n",
    "        super().__init__()\n",
    "                \n",
    "        self.dconv_down1 = double_conv(3, 64)\n",
    "        self.dconv_down2 = double_conv(64, 128)\n",
    "        self.dconv_down3 = double_conv(128, 256)\n",
    "        self.dconv_down4 = double_conv(256, 512)        \n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)        \n",
    "        \n",
    "        self.dconv_up3 = double_conv(256 + 512, 256)\n",
    "        self.dconv_up2 = double_conv(128 + 256, 128)\n",
    "        self.dconv_up1 = double_conv(128 + 64, 64)\n",
    "        \n",
    "        \n",
    "        self.dconv_up0 = double_conv(6*64, 3*64)\n",
    "        self.dconv_up00 = double_conv(3*64,64)\n",
    "        \n",
    "        self.conv_last = nn.Conv2d(64, n_class, 1)\n",
    "        \n",
    "        \n",
    "    def forward_once(self, x):\n",
    "        conv1 = self.dconv_down1(x)\n",
    "        x = self.maxpool(conv1)\n",
    "\n",
    "\n",
    "        conv2 = self.dconv_down2(x)\n",
    "        x = self.maxpool(conv2)\n",
    "\n",
    "        \n",
    "        conv3 = self.dconv_down3(x)\n",
    "        x = self.maxpool(conv3)  \n",
    "\n",
    "        \n",
    "        x = self.dconv_down4(x)\n",
    "\n",
    "        \n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv3], dim=1)\n",
    "\n",
    "        \n",
    "        x = self.dconv_up3(x)\n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv2], dim=1)   \n",
    "\n",
    "        x = self.dconv_up2(x)\n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv1], dim=1)   \n",
    "        \n",
    "        x = self.dconv_up1(x)\n",
    "        return x\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = [self.forward_once(y) for y in x]\n",
    "        x = torch.cat(x,axis=1)\n",
    "        \n",
    "        x = self.upsample(x)\n",
    "        x = self.dconv_up0(x)\n",
    "        \n",
    "        x = self.upsample(x)\n",
    "        x = self.dconv_up00(x)\n",
    "        \n",
    "        out = self.conv_last(x)\n",
    "        \n",
    "        return torch.sigmoid(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "    \n",
    "model = UNet(2).to(device)\n",
    "# Setting the optimiser\n",
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=learning_rate,\n",
    "    betas=(0.5, 0.999)\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n",
    "                                                       mode='min', \n",
    "                                                       factor=0.1, \n",
    "                                                       patience=5,\n",
    "                                                       verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(pred, target, smooth = 1.):\n",
    "    pred = pred.contiguous()\n",
    "    target = target.contiguous()    \n",
    "\n",
    "    intersection = (pred * target).sum(dim=2).sum(dim=2)\n",
    "    \n",
    "    loss = (1 - ((2. * intersection + smooth) / (pred.sum(dim=2).sum(dim=2) + target.sum(dim=2).sum(dim=2) + smooth)))\n",
    "    \n",
    "    return loss.mean()\n",
    "\n",
    "# Reconstruction + KL divergence losses summed over all elements and batch\n",
    "\n",
    "def loss_function(x_hat, x, epoch=None):\n",
    "    #only weighted bCE for first 8 epochs\n",
    "    if epoch!=None and epoch < 15:\n",
    "        #weighted\n",
    "        weight = torch.tensor([1, 1000])\n",
    "        weight_ = weight[x.data.view(-1).long()].view_as(x).to(device)\n",
    "        BCE = nn.functional.binary_cross_entropy(\n",
    "            x_hat, x, reduction='none'\n",
    "        )\n",
    "        BCE = (BCE*weight_).mean()\n",
    "    else:\n",
    "        BCE = nn.functional.binary_cross_entropy(\n",
    "            x_hat, x, reduction='mean'\n",
    "        )\n",
    "    \n",
    "    DICE = dice_loss(x_hat, x)\n",
    "\n",
    "    return BCE + DICE\n",
    "\n",
    "\n",
    "# Training and testing the VAE\n",
    "\n",
    "road_accuracy_list = []\n",
    "bb_accuracy_list = []\n",
    "best_loss = 1000000000\n",
    "threshold = 0.5\n",
    "epochs = 25\n",
    "for epoch in range(0, epochs + 1):\n",
    "    # Training\n",
    "    if epoch >= 0:  # test untrained net first\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for i, data in enumerate(trainloader):\n",
    "            sample, target, road_image, extra = data\n",
    "            batch_size = len(road_image)\n",
    "            x = torch.zeros((batch_size,2,800,800))\n",
    "            x[:,0,:,:] = 1.0*torch.stack(road_image).reshape(-1, 800, 800)\n",
    "            x[:,1,:,:] = torch.zeros((batch_size,800,800))\n",
    "            for i in range(batch_size):\n",
    "                for cat, bb in zip(target[i]['category'], target[i]['bounding_box']):\n",
    "                    x[i,1,:,:] = 1.0*convert_to_binary_mask(bb)\n",
    "            x = x.to(device)\n",
    "            y = torch.stack(sample).reshape(6,-1,3,200,200).to(device)\n",
    "            # ===================forward=====================\n",
    "            x_hat = model(y)\n",
    "            loss = loss_function(x_hat, x, epoch)\n",
    "            train_loss += loss.item()\n",
    "            # ===================backward====================\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        # ===================log========================\n",
    "        print(f'====> Epoch: {epoch} Average loss: {train_loss / len(trainloader.dataset):.4f}')\n",
    "\n",
    "    means, logvars, labels = list(), list(), list()\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        correct = [0,0]\n",
    "        total = [0,0]\n",
    "        conf_matrices = [torch.zeros(2,2).to(device),torch.zeros(2,2).to(device)]\n",
    "        for batch_idx, data in enumerate(testloader):\n",
    "            sample, target, road_image, extra = data\n",
    "            batch_size = len(road_image)\n",
    "            x = torch.zeros((batch_size,2,800,800))\n",
    "            x[:,0,:,:] = 1.0*torch.stack(road_image).reshape(-1, 800, 800)\n",
    "            x[:,1,:,:] = torch.zeros((batch_size,800,800))\n",
    "            for i in range(batch_size):\n",
    "                for cat, bb in zip(target[i]['category'], target[i]['bounding_box']):\n",
    "                    x[i,1,:,:] = 1.0*convert_to_binary_mask(bb)\n",
    "            x = x.to(device) \n",
    "            y = torch.stack(sample).reshape(6,-1,3,200,200).to(device)\n",
    "            \n",
    "            # ===================forward=====================\n",
    "            x_hat = model.inference(y)\n",
    "            test_loss += loss_function(x_hat, x).item()\n",
    "            # =====================log=======================\n",
    "            \n",
    "            for i in [0,1]:\n",
    "                print('='*100)\n",
    "                print('Channel:{}'.format(i))\n",
    "                correct[i] += (x_hat[:,i,:,:]>threshold).eq(\n",
    "                    (x[:,i,:,:]==1).data.view_as((\n",
    "                        x_hat[:,i,:,:]>threshold))).cpu().sum().item()\n",
    "                total[i] += x[:,i,:,:].nelement()\n",
    "\n",
    "                if batch_idx % 100 == 0:\n",
    "                    for k in range(0,60):\n",
    "                        thld = 0.2+k*0.01\n",
    "                        print('Confusion Matrix (Post) at threshold: {} for Channel {}'.format(thld, i))\n",
    "                        print(create_conf_matrix2(1*(x[:,i,:,:]==1), 1*(x_hat[:,i,:,:]>thld)))\n",
    "                        print('='*50)\n",
    "                    print('='*75)\n",
    "                conf_matrices[i] += create_conf_matrix2(1*(x[:,i,:,:]==1), 1*(x_hat[:,i,:,:]>threshold))\n",
    "                print('='*100)\n",
    "            \n",
    "                       \n",
    "    road_accuracy = 100. * correct[0] / total[0]\n",
    "    bb_accuracy = 100. * correct[1] / total[1]\n",
    "    \n",
    "    if test_loss < best_loss:\n",
    "        print('Updating best model')\n",
    "        best_loss = copy.deepcopy(test_loss)\n",
    "        best_model = copy.deepcopy(model)\n",
    "        torch.save(best_model.state_dict(), \n",
    "                   'models/unet_dual_model.pth')\n",
    "\n",
    "        \n",
    "    scheduler.step(test_loss)\n",
    "    road_accuracy_list.append(road_accuracy)\n",
    "    bb_accuracy_list.append(bb_accuracy)\n",
    "    print(\"\"\"\\nTest set: Average loss: {:.4f}, \n",
    "    Accuracy Road: {}/{} ({:.0f}%) ,\n",
    "    Accuracy BB: {}/{} ({:.0f}%) ,\n",
    "    Road: \n",
    "    TP {} , \n",
    "    TN {}\n",
    "    FP {}\n",
    "    FN {}\"\"\".format(\n",
    "        test_loss, \n",
    "        correct[0], total[0], road_accuracy,\n",
    "        correct[1], total[1], bb_accuracy,\n",
    "        *classScores(conf_matrix_road)))\n",
    "\n",
    "            #labels.append(y.detach())\n",
    "    # ===================log========================\n",
    "    #codes['y'].append(torch.cat(labels))\n",
    "    test_loss /= len(testloader.dataset)\n",
    "    print(f'====> Test set loss: {test_loss:.4f}')\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow((x[0,0,:,:].squeeze()==1).detach().cpu().numpy(), cmap='binary')\n",
    "    plt.imshow((x[0,1,:,:].squeeze()==1).detach().cpu().numpy(), cmap='binary')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow((x_hat[0,0,:,:].squeeze()>threshold).detach().cpu().numpy(), cmap='binary')\n",
    "    plt.imshow((x_hat[0,1,:,:].squeeze()>threshold).detach().cpu().numpy(), cmap='binary')\n",
    "    plt.savefig(\"imgs/unet_dual_plot_epoch_\"+str(epoch)+\".png\", dpi=150)\n",
    "    \n",
    "pd.DataFrame([road_accuracy_list,bb_accuracy_list], \n",
    "             columns=['road_accuracy','bb_accuracy']).to_csv('unet_dual_accuracy_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pDL",
   "language": "python",
   "name": "pdl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
