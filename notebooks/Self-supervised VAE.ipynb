{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from visdom import Visdom\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.contrib.examples.util import print_and_log\n",
    "from pyro.infer import SVI, JitTrace_ELBO, JitTraceEnum_ELBO, Trace_ELBO, TraceEnum_ELBO, config_enumerate\n",
    "from pyro.optim import Adam\n",
    "from utils.custom_mlp import MLP, Exp\n",
    "from utils.mnist_cached import MNISTCached, mkdir_p, setup_data_loaders\n",
    "from utils.vae_plots import mnist_test_tsne_ssvae, plot_conditional_samples_ssvae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSVAE(nn.Module):\n",
    "    \"\"\"\n",
    "    This class encapsulates the parameters (neural networks) and models & guides needed to train a\n",
    "    semi-supervised variational auto-encoder on the MNIST image dataset\n",
    "    :param output_size: size of the tensor representing the class label (10 for MNIST since\n",
    "                        we represent the class labels as a one-hot vector with 10 components)\n",
    "    :param input_size: size of the tensor representing the image (28*28 = 784 for our MNIST dataset\n",
    "                       since we flatten the images and scale the pixels to be in [0,1])\n",
    "    :param z_dim: size of the tensor representing the latent random variable z\n",
    "                  (handwriting style for our MNIST dataset)\n",
    "    :param hidden_layers: a tuple (or list) of MLP layers to be used in the neural networks\n",
    "                          representing the parameters of the distributions in our model\n",
    "    :param use_cuda: use GPUs for faster training\n",
    "    :param aux_loss_multiplier: the multiplier to use with the auxiliary loss\n",
    "    \"\"\"\n",
    "    def __init__(self, output_size=10, input_size=784, z_dim=50, hidden_layers=(500,),\n",
    "                 config_enum=None, use_cuda=False, aux_loss_multiplier=None):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        # initialize the class with all arguments provided to the constructor\n",
    "        self.output_size = output_size\n",
    "        self.input_size = input_size\n",
    "        self.z_dim = z_dim\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.allow_broadcast = config_enum == 'parallel'\n",
    "        self.use_cuda = use_cuda\n",
    "        self.aux_loss_multiplier = aux_loss_multiplier\n",
    "\n",
    "        # define and instantiate the neural networks representing\n",
    "        # the paramters of various distributions in the model\n",
    "        self.setup_networks()\n",
    "\n",
    "    def setup_networks(self):\n",
    "\n",
    "        z_dim = self.z_dim\n",
    "        hidden_sizes = self.hidden_layers\n",
    "\n",
    "        # define the neural networks used later in the model and the guide.\n",
    "        # these networks are MLPs (multi-layered perceptrons or simple feed-forward networks)\n",
    "        # where the provided activation parameter is used on every linear layer except\n",
    "        # for the output layer where we use the provided output_activation parameter\n",
    "        self.encoder_y = MLP([self.input_size] + hidden_sizes + [self.output_size],\n",
    "                             activation=nn.Softplus,\n",
    "                             output_activation=nn.Softmax,\n",
    "                             allow_broadcast=self.allow_broadcast,\n",
    "                             use_cuda=self.use_cuda)\n",
    "\n",
    "        # a split in the final layer's size is used for multiple outputs\n",
    "        # and potentially applying separate activation functions on them\n",
    "        # e.g. in this network the final output is of size [z_dim,z_dim]\n",
    "        # to produce loc and scale, and apply different activations [None,Exp] on them\n",
    "        self.encoder_z = MLP([self.input_size + self.output_size] +\n",
    "                             hidden_sizes + [[z_dim, z_dim]],\n",
    "                             activation=nn.Softplus,\n",
    "                             output_activation=[None, Exp],\n",
    "                             allow_broadcast=self.allow_broadcast,\n",
    "                             use_cuda=self.use_cuda)\n",
    "\n",
    "        self.decoder = MLP([z_dim + self.output_size] +\n",
    "                           hidden_sizes + [self.input_size],\n",
    "                           activation=nn.Softplus,\n",
    "                           output_activation=nn.Sigmoid,\n",
    "                           allow_broadcast=self.allow_broadcast,\n",
    "                           use_cuda=self.use_cuda)\n",
    "\n",
    "        # using GPUs for faster training of the networks\n",
    "        if self.use_cuda:\n",
    "            self.cuda()\n",
    "\n",
    "    def model(self, xs, ys=None):\n",
    "        \"\"\"\n",
    "        The model corresponds to the following generative process:\n",
    "        p(z) = normal(0,I)              # handwriting style (latent)\n",
    "        p(y|x) = categorical(I/10.)     # which digit (semi-supervised)\n",
    "        p(x|y,z) = bernoulli(loc(y,z))   # an image\n",
    "        loc is given by a neural network  `decoder`\n",
    "        :param xs: a batch of scaled vectors of pixels from an image\n",
    "        :param ys: (optional) a batch of the class labels i.e.\n",
    "                   the digit corresponding to the image(s)\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        # register this pytorch module and all of its sub-modules with pyro\n",
    "        pyro.module(\"ss_vae\", self)\n",
    "\n",
    "        batch_size = xs.size(0)\n",
    "        options = dict(dtype=xs.dtype, device=xs.device)\n",
    "        with pyro.plate(\"data\"):\n",
    "\n",
    "            # sample the handwriting style from the constant prior distribution\n",
    "            prior_loc = torch.zeros(batch_size, self.z_dim, **options)\n",
    "            prior_scale = torch.ones(batch_size, self.z_dim, **options)\n",
    "            zs = pyro.sample(\"z\", dist.Normal(prior_loc, prior_scale).to_event(1))\n",
    "\n",
    "            # if the label y (which digit to write) is supervised, sample from the\n",
    "            # constant prior, otherwise, observe the value (i.e. score it against the constant prior)\n",
    "            alpha_prior = torch.ones(batch_size, self.output_size, **options) / (1.0 * self.output_size)\n",
    "            ys = pyro.sample(\"y\", dist.OneHotCategorical(alpha_prior), obs=ys)\n",
    "\n",
    "            # finally, score the image (x) using the handwriting style (z) and\n",
    "            # the class label y (which digit to write) against the\n",
    "            # parametrized distribution p(x|y,z) = bernoulli(decoder(y,z))\n",
    "            # where `decoder` is a neural network\n",
    "            loc = self.decoder.forward([zs, ys])\n",
    "            pyro.sample(\"x\", dist.Bernoulli(loc).to_event(1), obs=xs)\n",
    "            # return the loc so we can visualize it later\n",
    "            return loc\n",
    "\n",
    "    def guide(self, xs, ys=None):\n",
    "        \"\"\"\n",
    "        The guide corresponds to the following:\n",
    "        q(y|x) = categorical(alpha(x))              # infer digit from an image\n",
    "        q(z|x,y) = normal(loc(x,y),scale(x,y))       # infer handwriting style from an image and the digit\n",
    "        loc, scale are given by a neural network `encoder_z`\n",
    "        alpha is given by a neural network `encoder_y`\n",
    "        :param xs: a batch of scaled vectors of pixels from an image\n",
    "        :param ys: (optional) a batch of the class labels i.e.\n",
    "                   the digit corresponding to the image(s)\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        # inform Pyro that the variables in the batch of xs, ys are conditionally independent\n",
    "        with pyro.plate(\"data\"):\n",
    "\n",
    "            # if the class label (the digit) is not supervised, sample\n",
    "            # (and score) the digit with the variational distribution\n",
    "            # q(y|x) = categorical(alpha(x))\n",
    "            if ys is None:\n",
    "                alpha = self.encoder_y.forward(xs)\n",
    "                ys = pyro.sample(\"y\", dist.OneHotCategorical(alpha))\n",
    "\n",
    "            # sample (and score) the latent handwriting-style with the variational\n",
    "            # distribution q(z|x,y) = normal(loc(x,y),scale(x,y))\n",
    "            loc, scale = self.encoder_z.forward([xs, ys])\n",
    "            pyro.sample(\"z\", dist.Normal(loc, scale).to_event(1))\n",
    "\n",
    "    def classifier(self, xs):\n",
    "        \"\"\"\n",
    "        classify an image (or a batch of images)\n",
    "        :param xs: a batch of scaled vectors of pixels from an image\n",
    "        :return: a batch of the corresponding class labels (as one-hots)\n",
    "        \"\"\"\n",
    "        # use the trained model q(y|x) = categorical(alpha(x))\n",
    "        # compute all class probabilities for the image(s)\n",
    "        alpha = self.encoder_y.forward(xs)\n",
    "\n",
    "        # get the index (digit) that corresponds to\n",
    "        # the maximum predicted class probability\n",
    "        res, ind = torch.topk(alpha, 1)\n",
    "\n",
    "        # convert the digit(s) to one-hot tensor(s)\n",
    "        ys = torch.zeros_like(alpha).scatter_(1, ind, 1.0)\n",
    "        return ys\n",
    "\n",
    "    def model_classify(self, xs, ys=None):\n",
    "        \"\"\"\n",
    "        this model is used to add an auxiliary (supervised) loss as described in the\n",
    "        Kingma et al., \"Semi-Supervised Learning with Deep Generative Models\".\n",
    "        \"\"\"\n",
    "        # register all pytorch (sub)modules with pyro\n",
    "        pyro.module(\"ss_vae\", self)\n",
    "\n",
    "        # inform Pyro that the variables in the batch of xs, ys are conditionally independent\n",
    "        with pyro.plate(\"data\"):\n",
    "            # this here is the extra term to yield an auxiliary loss that we do gradient descent on\n",
    "            if ys is not None:\n",
    "                alpha = self.encoder_y.forward(xs)\n",
    "                with pyro.poutine.scale(scale=self.aux_loss_multiplier):\n",
    "                    pyro.sample(\"y_aux\", dist.OneHotCategorical(alpha), obs=ys)\n",
    "\n",
    "    def guide_classify(self, xs, ys=None):\n",
    "        \"\"\"\n",
    "        dummy guide function to accompany model_classify in inference\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference_for_epoch(data_loaders, losses, periodic_interval_batches):\n",
    "    \"\"\"\n",
    "    runs the inference algorithm for an epoch\n",
    "    returns the values of all losses separately on supervised and unsupervised parts\n",
    "    \"\"\"\n",
    "    num_losses = len(losses)\n",
    "\n",
    "    # compute number of batches for an epoch\n",
    "    sup_batches = len(data_loaders[\"sup\"])\n",
    "    unsup_batches = len(data_loaders[\"unsup\"])\n",
    "    batches_per_epoch = sup_batches + unsup_batches\n",
    "\n",
    "    # initialize variables to store loss values\n",
    "    epoch_losses_sup = [0.] * num_losses\n",
    "    epoch_losses_unsup = [0.] * num_losses\n",
    "\n",
    "    # setup the iterators for training data loaders\n",
    "    sup_iter = iter(data_loaders[\"sup\"])\n",
    "    unsup_iter = iter(data_loaders[\"unsup\"])\n",
    "\n",
    "    # count the number of supervised batches seen in this epoch\n",
    "    ctr_sup = 0\n",
    "    for i in range(batches_per_epoch):\n",
    "\n",
    "        # whether this batch is supervised or not\n",
    "        is_supervised = (i % periodic_interval_batches == 1) and ctr_sup < sup_batches\n",
    "\n",
    "        # extract the corresponding batch\n",
    "        if is_supervised:\n",
    "            (xs, ys) = next(sup_iter)\n",
    "            ctr_sup += 1\n",
    "        else:\n",
    "            (xs, ys) = next(unsup_iter)\n",
    "\n",
    "        # run the inference for each loss with supervised or un-supervised\n",
    "        # data as arguments\n",
    "        for loss_id in range(num_losses):\n",
    "            if is_supervised:\n",
    "                new_loss = losses[loss_id].step(xs, ys)\n",
    "                epoch_losses_sup[loss_id] += new_loss\n",
    "            else:\n",
    "                new_loss = losses[loss_id].step(xs)\n",
    "                epoch_losses_unsup[loss_id] += new_loss\n",
    "\n",
    "    # return the values of all losses\n",
    "    return epoch_losses_sup, epoch_losses_unsup\n",
    "\n",
    "\n",
    "def get_accuracy(data_loader, classifier_fn, batch_size):\n",
    "    \"\"\"\n",
    "    compute the accuracy over the supervised training set or the testing set\n",
    "    \"\"\"\n",
    "    predictions, actuals = [], []\n",
    "\n",
    "    # use the appropriate data loader\n",
    "    for (xs, ys) in data_loader:\n",
    "        # use classification function to compute all predictions for each batch\n",
    "        predictions.append(classifier_fn(xs))\n",
    "        actuals.append(ys)\n",
    "\n",
    "    # compute the number of accurate predictions\n",
    "    accurate_preds = 0\n",
    "    for pred, act in zip(predictions, actuals):\n",
    "        for i in range(pred.size(0)):\n",
    "            v = torch.sum(pred[i] == act[i])\n",
    "            accurate_preds += (v.item() == 10)\n",
    "\n",
    "    # calculate the accuracy between 0 and 1\n",
    "    accuracy = (accurate_preds * 1.0) / (len(predictions) * batch_size)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def visualize(ss_vae, viz, test_loader):\n",
    "    if viz:\n",
    "        plot_conditional_samples_ssvae(ss_vae, viz)\n",
    "        mnist_test_tsne_ssvae(ssvae=ss_vae, test_loader=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.set_rng_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dim = 50\n",
    "hidden_layers = [50]\n",
    "cuda = torch.cuda.is_available()\n",
    "enum_discrete = None\n",
    "aux_loss_multiplier = 46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size: number of images (and labels) to be considered in a batch\n",
    "ss_vae = SSVAE(z_dim=z_dim,\n",
    "               hidden_layers=hidden_layers,\n",
    "               use_cuda=cuda,\n",
    "               config_enum=enum_discrete,\n",
    "               aux_loss_multiplier=aux_loss_multiplier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the optimizer\n",
    "adam_params = {\"lr\": args.learning_rate, \"betas\": (args.beta_1, 0.999)}\n",
    "optimizer = Adam(adam_params)\n",
    "\n",
    "# set up the loss(es) for inference. wrapping the guide in config_enumerate builds the loss as a sum\n",
    "# by enumerating each class label for the sampled discrete categorical distribution in the model\n",
    "guide = config_enumerate(ss_vae.guide, args.enum_discrete, expand=True)\n",
    "elbo = (JitTraceEnum_ELBO if args.jit else TraceEnum_ELBO)(max_plate_nesting=1)\n",
    "loss_basic = SVI(ss_vae.model, guide, optimizer, loss=elbo)\n",
    "\n",
    "# build a list of all losses considered\n",
    "losses = [loss_basic]\n",
    "\n",
    "# aux_loss: whether to use the auxiliary loss from NIPS 14 paper (Kingma et al)\n",
    "if args.aux_loss:\n",
    "    elbo = JitTrace_ELBO() if args.jit else Trace_ELBO()\n",
    "    loss_aux = SVI(ss_vae.model_classify, ss_vae.guide_classify, optimizer, loss=elbo)\n",
    "    losses.append(loss_aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "    try:\n",
    "        # setup the logger if a filename is provided\n",
    "        logger = open(args.logfile, \"w\") if args.logfile else None\n",
    "\n",
    "        data_loaders = setup_data_loaders(MNISTCached, args.cuda, args.batch_size, sup_num=args.sup_num)\n",
    "\n",
    "        # how often would a supervised batch be encountered during inference\n",
    "        # e.g. if sup_num is 3000, we would have every 16th = int(50000/3000) batch supervised\n",
    "        # until we have traversed through the all supervised batches\n",
    "        periodic_interval_batches = int(MNISTCached.train_data_size / (1.0 * args.sup_num))\n",
    "\n",
    "        # number of unsupervised examples\n",
    "        unsup_num = MNISTCached.train_data_size - args.sup_num\n",
    "\n",
    "        # initializing local variables to maintain the best validation accuracy\n",
    "        # seen across epochs over the supervised training set\n",
    "        # and the corresponding testing set and the state of the networks\n",
    "        best_valid_acc, corresponding_test_acc = 0.0, 0.0\n",
    "\n",
    "        # run inference for a certain number of epochs\n",
    "        for i in range(0, args.num_epochs):\n",
    "\n",
    "            # get the losses for an epoch\n",
    "            epoch_losses_sup, epoch_losses_unsup = \\\n",
    "                run_inference_for_epoch(data_loaders, losses, periodic_interval_batches)\n",
    "\n",
    "            # compute average epoch losses i.e. losses per example\n",
    "            avg_epoch_losses_sup = map(lambda v: v / args.sup_num, epoch_losses_sup)\n",
    "            avg_epoch_losses_unsup = map(lambda v: v / unsup_num, epoch_losses_unsup)\n",
    "\n",
    "            # store the loss and validation/testing accuracies in the logfile\n",
    "            str_loss_sup = \" \".join(map(str, avg_epoch_losses_sup))\n",
    "            str_loss_unsup = \" \".join(map(str, avg_epoch_losses_unsup))\n",
    "\n",
    "            str_print = \"{} epoch: avg losses {}\".format(i, \"{} {}\".format(str_loss_sup, str_loss_unsup))\n",
    "\n",
    "            validation_accuracy = get_accuracy(data_loaders[\"valid\"], ss_vae.classifier, args.batch_size)\n",
    "            str_print += \" validation accuracy {}\".format(validation_accuracy)\n",
    "\n",
    "            # this test accuracy is only for logging, this is not used\n",
    "            # to make any decisions during training\n",
    "            test_accuracy = get_accuracy(data_loaders[\"test\"], ss_vae.classifier, args.batch_size)\n",
    "            str_print += \" test accuracy {}\".format(test_accuracy)\n",
    "\n",
    "            # update the best validation accuracy and the corresponding\n",
    "            # testing accuracy and the state of the parent module (including the networks)\n",
    "            if best_valid_acc < validation_accuracy:\n",
    "                best_valid_acc = validation_accuracy\n",
    "                corresponding_test_acc = test_accuracy\n",
    "\n",
    "            print_and_log(logger, str_print)\n",
    "\n",
    "        final_test_accuracy = get_accuracy(data_loaders[\"test\"], ss_vae.classifier, args.batch_size)\n",
    "        print_and_log(logger, \"best validation accuracy {} corresponding testing accuracy {} \"\n",
    "                      \"last testing accuracy {}\".format(best_valid_acc, corresponding_test_acc, final_test_accuracy))\n",
    "\n",
    "        # visualize the conditional samples\n",
    "        visualize(ss_vae, viz, data_loaders[\"test\"])\n",
    "    finally:\n",
    "        # close the logger file object if we opened it earlier\n",
    "        if args.logfile:\n",
    "            logger.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pDL",
   "language": "python",
   "name": "pdl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
