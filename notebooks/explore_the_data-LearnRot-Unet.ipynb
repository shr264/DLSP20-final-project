{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 276596\n",
      "Train Epoch: 0 [0/76356 (0%)]\tLoss: 1.517550\n",
      "Train Epoch: 0 [16000/76356 (21%)]\tLoss: 0.000000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import time\n",
    "import sys\n",
    "import copy\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rcParams['figure.figsize'] = [5, 5]\n",
    "matplotlib.rcParams['figure.dpi'] = 200\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from data_helper import UnlabeledDataset, LabeledDataset\n",
    "from helper import collate_fn, draw_box\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from random import sample\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0);\n",
    "\n",
    "# All the images are saved in image_folder\n",
    "# All the labels are saved in the annotation_csv file\n",
    "\n",
    "##### ON PRINCE\n",
    "image_folder = '../../DLSP20Dataset/data'\n",
    "annotation_csv = '../../DLSP20Dataset/data/annotation.csv'\n",
    "\n",
    "\n",
    "##### ON WORK LAPTOP\n",
    "#image_folder = '/Users/rasy7001/Documents/DeepLearning/competition /data'\n",
    "#annotation_csv = '/Users/rasy7001/Documents/DeepLearning/competition /data'\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#device = 'cpu'\n",
    "\n",
    "torch.cuda.is_available()\n",
    "\n",
    "# function to count number of parameters\n",
    "def get_n_params(model):\n",
    "    np=0\n",
    "    for p in list(model.parameters()):\n",
    "        np += p.nelement()\n",
    "    return np\n",
    "\n",
    "def order_points(pts):\n",
    "    from scipy.spatial import distance as dist\n",
    "    import numpy as np\n",
    "    \n",
    "    xSorted = pts[np.argsort(pts[:, 0]), :]\n",
    "\n",
    "    leftMost = xSorted[:2, :]\n",
    "    rightMost = xSorted[2:, :]\n",
    "\n",
    "    leftMost = leftMost[np.argsort(leftMost[:, 1]), :]\n",
    "    (tl, bl) = leftMost\n",
    "\n",
    "    D = dist.cdist(tl[np.newaxis], rightMost, \"euclidean\")[0]\n",
    "    (br, tr) = rightMost[np.argsort(D)[::-1], :]\n",
    "\n",
    "    return np.array([tl, tr, br, bl], dtype=\"float32\")\n",
    "\n",
    "def arrange_box(x1,y1):\n",
    "    box=np.array(list(zip(x1,y1)))\n",
    "    box=order_points(box)\n",
    "    return box\n",
    "\n",
    "def iou(box1, box2):\n",
    "    from shapely.geometry import Polygon\n",
    "    a = Polygon(torch.t(box1)).convex_hull\n",
    "    b = Polygon(torch.t(box2)).convex_hull\n",
    "    \n",
    "    return a.intersection(b).area / a.union(b).area\n",
    "\n",
    "#def iou(xy1,xy2):\n",
    "#    \n",
    "#    from shapely.geometry import Polygon\n",
    "#    \n",
    "#    boxA = Polygon(arrange_box(xy1[0],xy1[1])).buffer(1e-9)\n",
    "#    boxB = Polygon(arrange_box(xy2[0],xy2[1])).buffer(1e-9)\n",
    "#    \n",
    "#    try:\n",
    "#        return boxA.intersection(boxB).area / boxA.union(boxB).area\n",
    "#    except:\n",
    "#        print('Box 1:',xy1[0],xy1[1])\n",
    "#        print('Box 2:',xy2[0],xy2[1])\n",
    "#        sys.exit(1)\n",
    "\n",
    "def map_to_ground_truth(overlaps, print_it=False):\n",
    "    prior_overlap, prior_idx = overlaps.max(1)\n",
    "    if print_it: print(prior_overlap)\n",
    "#     pdb.set_trace()\n",
    "    gt_overlap, gt_idx = overlaps.max(0)\n",
    "    gt_overlap[prior_idx] = 1.99\n",
    "    for i,o in enumerate(prior_idx): gt_idx[o] = i\n",
    "    return gt_overlap,gt_idx\n",
    "\n",
    "def calculate_overlap(target_bb, predicted_bb):\n",
    "    overlaps = torch.zeros(target_bb.size(0),predicted_bb.size(0))\n",
    "\n",
    "    for j in range(overlaps.shape[0]):\n",
    "        for k in range(overlaps.shape[1]):\n",
    "            overlaps[j][k] = iou(target_bb[j],predicted_bb[k])\n",
    "            \n",
    "    return overlaps\n",
    "\n",
    "def one_hot_embedding(labels, num_classes):\n",
    "    return torch.eye(num_classes)[labels.data.cpu()]\n",
    "\n",
    "from skimage import draw\n",
    "import numpy as np\n",
    "\n",
    "def poly2mask(vertex_row_coords, vertex_col_coords, shape):\n",
    "    fill_row_coords, fill_col_coords = draw.polygon(vertex_row_coords, vertex_col_coords, shape)\n",
    "    mask = torch.zeros(shape, dtype=np.bool)\n",
    "    mask[fill_row_coords, fill_col_coords] = True\n",
    "    return mask\n",
    "\n",
    "def convert_to_binary_mask(corners, shape=(800,800)):\n",
    "    point_squence = torch.stack([corners[:, 0], corners[:, 1], corners[:, 3], corners[:, 2], corners[:, 0]])\n",
    "    x,y = point_squence.T[0].detach() * 10 + 400, -point_squence.T[1].detach() * 10 + 400\n",
    "    new_im = poly2mask(y, x, shape)\n",
    "    return new_im\n",
    "\n",
    "def create_conf_matrix(target, pred, debug=True):\n",
    "    import sys\n",
    "    \n",
    "    target = target.reshape(-1)\n",
    "    pred = pred.reshape(-1)\n",
    "    \n",
    "    if debug:\n",
    "        print('Target values:', target.unique())\n",
    "        print('Predicted values:', pred.unique())\n",
    "        print('Target shape:', target.shape)\n",
    "        print('Predicted shape:', pred.shape)\n",
    "    \n",
    "    nb_classes = max(target.unique())\n",
    "    if len(pred.unique()) > (nb_classes+1) :\n",
    "        print('More predicted classes than true classes')\n",
    "        sys.exit(1)\n",
    "        \n",
    "    conf_matrix = torch.zeros(nb_classes+1, nb_classes+1)\n",
    "    for t, p in zip(target, pred):\n",
    "        conf_matrix[t, p] += 1\n",
    "    \n",
    "    return conf_matrix\n",
    "\n",
    "def create_conf_matrix2(target, pred, debug=True):\n",
    "    import sys\n",
    "    \n",
    "    target = target.reshape(-1).cpu().numpy()\n",
    "    pred = pred.reshape(-1).cpu().numpy()\n",
    "    \n",
    "        \n",
    "    conf_matrix = torch.from_numpy(confusion_matrix(target, pred)).to(device)\n",
    "    \n",
    "    return conf_matrix\n",
    "\n",
    "def classScores(conf_matrix):\n",
    "    print('Confusion matrix\\n', conf_matrix)\n",
    "    TP = conf_matrix.diag()\n",
    "    TN = torch.zeros_like(TP)\n",
    "    FP = torch.zeros_like(TP)\n",
    "    FN = torch.zeros_like(TP)\n",
    "    for c in range(conf_matrix.size(0)):\n",
    "        idx = torch.ones(conf_matrix.size(0)).byte()\n",
    "        idx[c] = 0\n",
    "        # all non-class samples classified as non-class\n",
    "        TN[c] = conf_matrix[idx.nonzero()[:, None], idx.nonzero()].sum() #conf_matrix[idx[:, None], idx].sum() - conf_matrix[idx, c].sum()\n",
    "        # all non-class samples classified as class\n",
    "        FP[c] = conf_matrix[idx, c].sum()\n",
    "        # all class samples not classified as class\n",
    "        FN[c] = conf_matrix[c, idx].sum()\n",
    "\n",
    "        print('Class {}\\nTP {}, TN {}, FP {}, FN {}'.format(\n",
    "            c, TP[c], TN[c], FP[c], FN[c]))\n",
    "        \n",
    "    return TP, TN, FP, FN\n",
    "\n",
    "\n",
    "\n",
    "# You shouldn't change the unlabeled_scene_index\n",
    "# The first 106 scenes are unlabeled\n",
    "unlabeled_scene_index = np.arange(106)\n",
    "# The scenes from 106 - 133 are labeled\n",
    "# You should devide the labeled_scene_index into two subsets (training and validation)\n",
    "labeled_scene_index = np.arange(106, 134)\n",
    "\n",
    "# training for rotation \n",
    "train_scene_index = np.random.choice(unlabeled_scene_index, int(np.ceil(0.95*len(unlabeled_scene_index))))\n",
    "\n",
    "# test for rotation \n",
    "test_scene_index = unlabeled_scene_index[np.isin(unlabeled_scene_index, train_scene_index, invert=True)]\n",
    "\n",
    "\n",
    "#transform = torchvision.transforms.ToTensor()\n",
    "\n",
    "#transform=torchvision.transforms.Compose([torchvision.transforms.RandomCrop((200,200)),\n",
    "#                                          torchvision.transforms.Resize((100,100)),\n",
    "##                                          torchvision.transforms.ToTensor(),\n",
    " #                             #torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    " #                            ])\n",
    "\n",
    "transform=torchvision.transforms.Compose([torchvision.transforms.Resize((200,200)),\n",
    "                                          torchvision.transforms.ToTensor(),\n",
    "#                              torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                             ])\n",
    "\n",
    "unlabeled_trainset = UnlabeledDataset(image_folder=image_folder, \n",
    "                                      scene_index=train_scene_index, \n",
    "                                      first_dim='sample', \n",
    "                                      transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(unlabeled_trainset, batch_size=16, shuffle=True, num_workers=2)\n",
    "\n",
    "unlabeled_testset = UnlabeledDataset(image_folder=image_folder, \n",
    "                                      scene_index=test_scene_index, \n",
    "                                      first_dim='sample', \n",
    "                                      transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(unlabeled_testset, batch_size=16, shuffle=True, num_workers=2)\n",
    "\n",
    "def double_conv(in_channels, out_channels):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "        nn.LeakyReLU(negative_slope=0.1),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        #nn.Dropout(0.5),\n",
    "        nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "        nn.LeakyReLU(negative_slope=0.1),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        #nn.Dropout(0.5)\n",
    "    ) \n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, d=650, output_size=4):\n",
    "        super().__init__()\n",
    "        self.dconv_down1 = double_conv(3, 16)\n",
    "        self.dconv_down2 = double_conv(16, 32)\n",
    "        self.dconv_down3 = double_conv(32, 48)\n",
    "        self.dconv_down4 = double_conv(48, 64)        \n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        self.linear = nn.Linear(64*25*25,4)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        conv1 = self.dconv_down1(x)\n",
    "        x = self.maxpool(conv1)\n",
    "\n",
    "\n",
    "        conv2 = self.dconv_down2(x)\n",
    "        x = self.maxpool(conv2)\n",
    "\n",
    "        \n",
    "        conv3 = self.dconv_down3(x)\n",
    "        x = self.maxpool(conv3)  \n",
    "\n",
    "        \n",
    "        x = self.dconv_down4(x)\n",
    "        #print(x.shape)\n",
    "        x = self.linear(x.reshape(-1,64*25*25))\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "NUM_SAMPLE_PER_SCENE = 126\n",
    "NUM_IMAGE_PER_SAMPLE = 6\n",
    "image_names = [\n",
    "    'CAM_FRONT_LEFT.jpeg',\n",
    "    'CAM_FRONT.jpeg',\n",
    "    'CAM_FRONT_RIGHT.jpeg',\n",
    "    'CAM_BACK_LEFT.jpeg',\n",
    "    'CAM_BACK.jpeg',\n",
    "    'CAM_BACK_RIGHT.jpeg',\n",
    "    ]\n",
    "\n",
    "# The dataset class for unlabeled data.\n",
    "class UnlabeledRotationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_folder, scene_index, first_dim, transform):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image_folder (string): the location of the image folder\n",
    "            scene_index (list): a list of scene indices for the unlabeled data \n",
    "            first_dim ({'sample', 'image'}):\n",
    "                'sample' will return [batch_size, NUM_IMAGE_PER_SAMPLE, 3, H, W]\n",
    "                'image' will return [batch_size, 3, H, W] and the index of the camera [0 - 5]\n",
    "                    CAM_FRONT_LEFT: 0\n",
    "                    CAM_FRONT: 1\n",
    "                    CAM_FRONT_RIGHT: 2\n",
    "                    CAM_BACK_LEFT: 3\n",
    "                    CAM_BACK.jpeg: 4\n",
    "                    CAM_BACK_RIGHT: 5\n",
    "            transform (Transform): The function to process the image\n",
    "        \"\"\"\n",
    "\n",
    "        self.image_folder = image_folder\n",
    "        self.scene_index = scene_index\n",
    "        self.transform = transform\n",
    "\n",
    "        self.first_dim = 'image'\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.first_dim == 'sample':\n",
    "            return self.scene_index.size * NUM_SAMPLE_PER_SCENE\n",
    "        elif self.first_dim == 'image':\n",
    "            return self.scene_index.size * NUM_SAMPLE_PER_SCENE * NUM_IMAGE_PER_SAMPLE\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if self.first_dim == 'sample':\n",
    "            scene_id = self.scene_index[index // NUM_SAMPLE_PER_SCENE]\n",
    "            sample_id = index % NUM_SAMPLE_PER_SCENE\n",
    "            sample_path = os.path.join(self.image_folder, f'scene_{scene_id}', f'sample_{sample_id}') \n",
    "\n",
    "            images = []\n",
    "            labels = []\n",
    "            for image_name in image_names:\n",
    "                \n",
    "                rot_class = np.random.randint(4)\n",
    "                rot_angle = rot_class * 90\n",
    "                \n",
    "                image_path = os.path.join(sample_path, image_name)\n",
    "                image = Image.open(image_path)\n",
    "                rot_image = image.rotate(rot_angle)\n",
    "                labels.append(torch.from_numpy(np.asarray(rot_class)))\n",
    "                images.append(self.transform(image))\n",
    "            \n",
    "            image_tensor = torch.stack(images)\n",
    "            label_tensor = torch.stack(labels)\n",
    "            \n",
    "            return image_tensor, label_tensor\n",
    "            \n",
    "        elif self.first_dim == 'image':\n",
    "            scene_id = self.scene_index[index // (NUM_SAMPLE_PER_SCENE * NUM_IMAGE_PER_SAMPLE)]\n",
    "            sample_id = (index % (NUM_SAMPLE_PER_SCENE * NUM_IMAGE_PER_SAMPLE)) // NUM_IMAGE_PER_SAMPLE\n",
    "            image_name = image_names[index % NUM_IMAGE_PER_SAMPLE]\n",
    "\n",
    "            image_path = os.path.join(self.image_folder, f'scene_{scene_id}', f'sample_{sample_id}', image_name) \n",
    "\n",
    "            rot_class = np.random.randint(4)\n",
    "            rot_angle = rot_class * 90\n",
    "            image = Image.open(image_path)\n",
    "            rot_image = image.rotate(rot_angle)\n",
    "\n",
    "            return self.transform(rot_image), torch.from_numpy(np.asarray(rot_class)), index % NUM_IMAGE_PER_SAMPLE\n",
    "            \n",
    "\n",
    "## Get individual image\n",
    "\n",
    "unlabeled_trainset = UnlabeledDataset(image_folder=image_folder, \n",
    "                                      scene_index=unlabeled_scene_index, \n",
    "                                      first_dim='image', \n",
    "                                      transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(unlabeled_trainset, batch_size=2, shuffle=True, num_workers=2)\n",
    "\n",
    "# Rotation Representation Learning\n",
    "\n",
    "batch_size=16\n",
    "\n",
    "unlabeled_trainset = UnlabeledRotationDataset(image_folder=image_folder, \n",
    "                                      scene_index=train_scene_index, \n",
    "                                      first_dim='image', \n",
    "                                      transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(unlabeled_trainset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "unlabeled_testset = UnlabeledRotationDataset(image_folder=image_folder, \n",
    "                                      scene_index=test_scene_index, \n",
    "                                      first_dim='image', \n",
    "                                      transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(unlabeled_testset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "sample, label, img_index = iter(trainloader).next()\n",
    "\n",
    "model_cnn = CNN()\n",
    "model_cnn = model_cnn.to(device)\n",
    "\n",
    "accuracy_list = []\n",
    "best_loss = 1000000\n",
    "\n",
    "model_cnn = CNN()\n",
    "model_cnn.to(device)\n",
    "best_model = copy.deepcopy(model_cnn)\n",
    "\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(\n",
    "    model_cnn.parameters(),\n",
    "    lr=learning_rate,\n",
    "    betas=(0.5, 0.999)\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n",
    "                                                       mode='min', \n",
    "                                                       factor=0.1, \n",
    "                                                       patience=5,\n",
    "                                                       verbose=True)\n",
    "print('Number of parameters: {}'.format(get_n_params(model_cnn)))\n",
    "\n",
    "def train(epoch, model):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target, data_idx) in enumerate(trainloader):\n",
    "        # send to device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 1000 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(trainloader.dataset),\n",
    "                100. * batch_idx / len(trainloader), loss.item()))\n",
    "            \n",
    "def test(model):\n",
    "    global best_loss, best_model\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target, data_idx in testloader:\n",
    "        # send to device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss                                                               \n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability                                                                 \n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum().item()\n",
    "\n",
    "    test_loss /= len(testloader.dataset)\n",
    "    accuracy = 100. * correct / len(testloader.dataset)\n",
    "    accuracy_list.append(accuracy)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(testloader.dataset),\n",
    "        accuracy))\n",
    "    if test_loss < best_loss:\n",
    "        print('Updating best model')\n",
    "        best_loss = copy.deepcopy(test_loss)\n",
    "        best_model = copy.deepcopy(model)\n",
    "        torch.save(best_model.state_dict(), 'models/rotation_learning_model_unet.pth')\n",
    "        \n",
    "    return test_loss\n",
    "        \n",
    "for epoch in range(0, 25):\n",
    "    train(epoch, model_cnn)\n",
    "    test_loss = test(model_cnn)\n",
    "    scheduler.step(test_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pDL",
   "language": "python",
   "name": "pdl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
